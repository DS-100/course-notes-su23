<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Principles and Techniques of Data Science - 22&nbsp; PCA I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../pca_2/pca_2.html" rel="next">
<link href="../sql_II/sql_II.html" rel="prev">
<link href="../data100_logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../pca_1/pca_1.html"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">PCA I</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../data100_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Principles and Techniques of Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/DS-100/course-notes-su23" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_lec/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_1/pandas_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Pandas I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_2/pandas_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Pandas II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_3/pandas_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pandas III</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../eda/eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Cleaning and EDA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regex/regex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Text Wrangling and Regular Expressions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../visualization_1/visualization_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Visualization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling/sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_to_modeling/intro_to_modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../constant_model_loss_transformations/loss_transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Constant Model, Loss, and Transformations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ols/ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../gradient_descent/gradient_descent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../feature_engineering/feature_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Sklearn and Feature Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../case_study_HCE/case_study_HCE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Case Study in Human Contexts and Ethics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cv_regularization/cv_reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Cross Validation and Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_1/probability_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_2/probability_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Bias, Variance, and Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_1/logistic_reg_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_2/logistic_reg_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Logistic Regression II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_I/sql_I.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">SQL I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_II/sql_II.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">SQL II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_1/pca_1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">PCA I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_2/pca_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">PCA II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../decision_tree/decision_tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Decision Trees</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#dimensionality-reduction" id="toc-dimensionality-reduction" class="nav-link active" data-scroll-target="#dimensionality-reduction"><span class="header-section-number">22.1</span> Dimensionality Reduction</a>
  <ul>
  <li><a href="#visualizing-high-dimensional-data" id="toc-visualizing-high-dimensional-data" class="nav-link" data-scroll-target="#visualizing-high-dimensional-data"><span class="header-section-number">22.1.1</span> Visualizing High Dimensional Data</a></li>
  <li><a href="#dimensionality" id="toc-dimensionality" class="nav-link" data-scroll-target="#dimensionality"><span class="header-section-number">22.1.2</span> Dimensionality</a></li>
  <li><a href="#reducing-dimensionality" id="toc-reducing-dimensionality" class="nav-link" data-scroll-target="#reducing-dimensionality"><span class="header-section-number">22.1.3</span> Reducing dimensionality</a></li>
  </ul></li>
  <li><a href="#pca-goal-and-motivation" id="toc-pca-goal-and-motivation" class="nav-link" data-scroll-target="#pca-goal-and-motivation"><span class="header-section-number">22.2</span> PCA: Goal and Motivation</a>
  <ul>
  <li><a href="#capturing-total-variance" id="toc-capturing-total-variance" class="nav-link" data-scroll-target="#capturing-total-variance"><span class="header-section-number">22.2.1</span> Capturing Total Variance</a></li>
  <li><a href="#goal-and-motivation" id="toc-goal-and-motivation" class="nav-link" data-scroll-target="#goal-and-motivation"><span class="header-section-number">22.2.2</span> Goal and Motivation</a></li>
  <li><a href="#procedural-overview" id="toc-procedural-overview" class="nav-link" data-scroll-target="#procedural-overview"><span class="header-section-number">22.2.3</span> Procedural Overview</a></li>
  </ul></li>
  <li><a href="#singular-value-decomposition" id="toc-singular-value-decomposition" class="nav-link" data-scroll-target="#singular-value-decomposition"><span class="header-section-number">22.3</span> Singular Value Decomposition</a>
  <ul>
  <li><a href="#matrix-as-transformation" id="toc-matrix-as-transformation" class="nav-link" data-scroll-target="#matrix-as-transformation"><span class="header-section-number">22.3.1</span> Matrix as Transformation</a></li>
  <li><a href="#orthonormality-and-diagonal-matrices" id="toc-orthonormality-and-diagonal-matrices" class="nav-link" data-scroll-target="#orthonormality-and-diagonal-matrices"><span class="header-section-number">22.3.2</span> Orthonormality and Diagonal Matrices</a></li>
  <li><a href="#svd" id="toc-svd" class="nav-link" data-scroll-target="#svd"><span class="header-section-number">22.3.3</span> SVD</a></li>
  <li><a href="#svd-in-numpy" id="toc-svd-in-numpy" class="nav-link" data-scroll-target="#svd-in-numpy"><span class="header-section-number">22.3.4</span> SVD in <code>NumPy</code></a></li>
  </ul></li>
  <li><a href="#pca-with-svd" id="toc-pca-with-svd" class="nav-link" data-scroll-target="#pca-with-svd"><span class="header-section-number">22.4</span> PCA with SVD</a>
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">22.4.1</span> Summary</a></li>
  <li><a href="#pca-in-numpy" id="toc-pca-in-numpy" class="nav-link" data-scroll-target="#pca-in-numpy"><span class="header-section-number">22.4.2</span> PCA in <code>NumPy</code></a>
  <ul>
  <li><a href="#step-1-center-the-data-matrix-x" id="toc-step-1-center-the-data-matrix-x" class="nav-link" data-scroll-target="#step-1-center-the-data-matrix-x"><span class="header-section-number">22.4.2.1</span> Step 1: Center the data matrix <span class="math inline">\(X\)</span></a></li>
  <li><a href="#step-2-get-the-svd-of-the-centered-x" id="toc-step-2-get-the-svd-of-the-centered-x" class="nav-link" data-scroll-target="#step-2-get-the-svd-of-the-centered-x"><span class="header-section-number">22.4.2.2</span> Step 2: Get the SVD of the centered <span class="math inline">\(X\)</span></a></li>
  <li><a href="#step-3-multiply-either-usigma-or-xv" id="toc-step-3-multiply-either-usigma-or-xv" class="nav-link" data-scroll-target="#step-3-multiply-either-usigma-or-xv"><span class="header-section-number">22.4.2.3</span> Step 3: Multiply either <span class="math inline">\(U\Sigma\)</span> or <span class="math inline">\(XV\)</span></a></li>
  <li><a href="#step-4-get-the-first-k-columns" id="toc-step-4-get-the-first-k-columns" class="nav-link" data-scroll-target="#step-4-get-the-first-k-columns"><span class="header-section-number">22.4.2.4</span> Step 4: Get the first <span class="math inline">\(k\)</span> columns</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#data-variance-and-centering" id="toc-data-variance-and-centering" class="nav-link" data-scroll-target="#data-variance-and-centering"><span class="header-section-number">22.5</span> Data Variance and Centering</a>
  <ul>
  <li><a href="#variance-with-singular-values" id="toc-variance-with-singular-values" class="nav-link" data-scroll-target="#variance-with-singular-values"><span class="header-section-number">22.5.1</span> Variance with Singular Values</a></li>
  <li><a href="#centering" id="toc-centering" class="nav-link" data-scroll-target="#centering"><span class="header-section-number">22.5.2</span> Centering</a></li>
  <li><a href="#bonus-proof-of-component-score" id="toc-bonus-proof-of-component-score" class="nav-link" data-scroll-target="#bonus-proof-of-component-score"><span class="header-section-number">22.5.3</span> (Bonus) Proof of component score</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">PCA I</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Outcomes
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Introduce principles of unsupervised learning</li>
<li>Define and carry out procedure of PCA</li>
<li>Understand connection between PCA and SVD</li>
</ul>
</div>
</div>
<p>We are now in our second pass of the data science lifecycle: we introduced a new tool to carry out exploratory data analysis (EDA)—SQL—in the last two lectures. Now we will continue and look at a tool useful for both EDA and modeling.</p>
<section id="dimensionality-reduction" class="level2" data-number="22.1">
<h2 data-number="22.1" class="anchored" data-anchor-id="dimensionality-reduction"><span class="header-section-number">22.1</span> Dimensionality Reduction</h2>
<section id="visualizing-high-dimensional-data" class="level3" data-number="22.1.1">
<h3 data-number="22.1.1" class="anchored" data-anchor-id="visualizing-high-dimensional-data"><span class="header-section-number">22.1.1</span> Visualizing High Dimensional Data</h3>
<p>One of the first things we do in EDA is visualization. Visualization can give us a rough idea how similar/dissimilar some the data points are. For example, let’s consider the following dataset about genes. Each row represents an individual, and each column represents a gene expression. We can visualize the first feature using a rug plot.</p>
<div class="columns">
<div class="column" style="width:40%;">
<table class="table">
<thead>
<tr class="header">
<th>Gene 1</th>
<th>Gene 2</th>
<th>Gene 3</th>
<th>Gene 4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>10</td>
<td>6</td>
<td>12</td>
<td>5</td>
</tr>
<tr class="even">
<td>11</td>
<td>4</td>
<td>9</td>
<td>7</td>
</tr>
<tr class="odd">
<td>8</td>
<td>5</td>
<td>10</td>
<td>6</td>
</tr>
<tr class="even">
<td>3</td>
<td>3</td>
<td>2.5</td>
<td>2</td>
</tr>
<tr class="odd">
<td>2</td>
<td>2.8</td>
<td>1.3</td>
<td>4</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>2</td>
<td>7</td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:55%;">
<p><img src="images/1d.png" alt="1D Visualization of Gene data" width="400"></p>
</div>
</div>
<p>We can see clearly that there are two “clusters” of points: one with lower <code>Gene 1</code> values; one with higher <code>Gene 1</code> values. Furthermore, we can visualize two or more features and the clusters are still present.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img src="images/2d.png" alt="2D Visualization of Gene data" width="400"></p>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:45%;">
<p><img src="images/3d.png" alt="3D Visualization of Gene data" width="350"></p>
</div>
</div>
<p>Since we are all 3-dimensional beings, we can’t visualize beyond three dimensions! However, many datasets come with more than three features. What can we do?</p>
<p>A lot of the times in EDA, we perform <strong>dimensionality reduction</strong> to reduce our dataset to lower dimensions, so we can easily visualize it.</p>
</section>
<section id="dimensionality" class="level3" data-number="22.1.2">
<h3 data-number="22.1.2" class="anchored" data-anchor-id="dimensionality"><span class="header-section-number">22.1.2</span> Dimensionality</h3>
<p>What do we mean by dimensionality reduction? In particular, what is dimensionality?</p>
<p>Previously, we have been working with data tables with rows and columns. Now, we have to be a bit more clear with our wording to follow the language of linear algebra.</p>
<p>Suppose we have a dataset of:</p>
<ul>
<li><span class="math inline">\(N\)</span> observations (data points/rows)</li>
<li><span class="math inline">\(d\)</span> attributes (features/columns).</li>
</ul>
<p>Linear Algebra views our data as a matrix:</p>
<ul>
<li><span class="math inline">\(N\)</span> row vectors in a <span class="math inline">\(d\)</span>-dimensional space; or</li>
<li><span class="math inline">\(d\)</span> column vectors in an <span class="math inline">\(N\)</span>-dimensional space.</li>
</ul>
<p>In Linear Algebra, the dimension of a matrix is usually its column <strong>rank</strong>. In Data Science, we will mostly follow this definition, but we have slightly more things to consider.</p>
<p>If we have a dataset about weights, with two columns measuring the same weights in different units (lbs and kg). We will say the dimension of this data matrix is <span class="math inline">\(1\)</span>, because the column rank of this matrix is <span class="math inline">\(1\)</span>. We can visualize this data matrix and see that the data points are indeed 1-dimensional—they lie on a single line.</p>
<div class="columns">
<div class="column" style="width:40%;">
<table class="table">
<thead>
<tr class="header">
<th>Weight (lbs)</th>
<th>Weight (kg)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>113.0</td>
<td>51.3</td>
</tr>
<tr class="even">
<td>136.5</td>
<td>61.9</td>
</tr>
<tr class="odd">
<td>153.0</td>
<td>69.4</td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:55%;">
<p><img src="images/weights_1d.png" alt="Visualization of Weights Data" width="400"></p>
</div>
</div>
<p>If we add an outlier to this dataset (might be due to a measurement error), however, the rank of the matrix would be <span class="math inline">\(2\)</span>, but because of the nature of the dataset, we would still consider the dimension of this dataset <span class="math inline">\(1\)</span>.</p>
<p><img src="images/weights_outlier.png" alt="Visualization of Weights Data with an outlier" width="400"></p>
</section>
<section id="reducing-dimensionality" class="level3" data-number="22.1.3">
<h3 data-number="22.1.3" class="anchored" data-anchor-id="reducing-dimensionality"><span class="header-section-number">22.1.3</span> Reducing dimensionality</h3>
<p>How do we reduce the dimension of a data matrix? We usually do this by projecting the dataset onto a lower dimensional space. There are many different ways we can project. Using the Gene data we’ve seen earlier, we can project all the data points on to the feature <code>Gene 1</code>, or the feature <code>Gene 2</code>.</p>
<div class="columns">
<div class="column" style="width:47%;">
<p><img src="images/projection1.png" alt="Projecting Gene data onto Gene 1" width="400"></p>
</div><div class="column" style="width:6%;">

</div><div class="column" style="width:47%;">
<p><img src="images/projection2.png" alt="Projecting Gene data onto Gene 1" width="400"></p>
</div>
</div>
<p>We don’t have to project onto a feature though. For example, we can project the points onto an arbitrary line:</p>
<p><img src="images/projection3.png" alt="Projecting Gene data onto an arbitrary line" width="400"></p>
<p>There are so many possible projections—how do we know which one to choose?</p>
<p>In general, we want the projection that is the <em>best approximation</em> for the original data. In other words, we want the projection that capture the <em>most variance</em> of the original data. The method we use to get such a projection is Principal Component Analysis (PCA).</p>
</section>
</section>
<section id="pca-goal-and-motivation" class="level2" data-number="22.2">
<h2 data-number="22.2" class="anchored" data-anchor-id="pca-goal-and-motivation"><span class="header-section-number">22.2</span> PCA: Goal and Motivation</h2>
<p>Let’s first see what our goals are when we are performing PCA and why we want to do it in practice.</p>
<section id="capturing-total-variance" class="level3" data-number="22.2.1">
<h3 data-number="22.2.1" class="anchored" data-anchor-id="capturing-total-variance"><span class="header-section-number">22.2.1</span> Capturing Total Variance</h3>
<p>We mentioned in the last section that we want to find the projection that capture the <em>most variance</em> of the original data. What do we mean by “variance”?</p>
<p>Similar to what we’ve seen before, variability of the data is the most important aspect that we want to maintain. It is the bulk of what we care about when we conduct EDA and modeling.</p>
<p>The <strong>total variance</strong> for a data matrix is defined as the sum of variances of its columns. To get the total variance of a data matrix, we get the variance of each column individually, and then sum them up.</p>
<p>To capture the “most variance,” one approach is to simply keep the columns with the highest variance—this is similar to what we did above with the Gene dataset where we project the data onto the feature <code>Gene 1</code>. This will sometimes work fine, but we want to do better.</p>
<p>It turns out that PCA does a better job at preserving variances. In fact, PCA will give us the projection that captures the most variances, out of all possible dimensionality reductions of the data matrix.</p>
</section>
<section id="goal-and-motivation" class="level3" data-number="22.2.2">
<h3 data-number="22.2.2" class="anchored" data-anchor-id="goal-and-motivation"><span class="header-section-number">22.2.2</span> Goal and Motivation</h3>
<p>The goal of PCA is to transform observations from high-dimensional data down to low dimensions (often 2) through linear transformations of the columns. In particular, we want to find a linear transformation that creates a low-dimension representation which captures as much of the original data’s total variance as possible.</p>
<p>Why do we want to do this? We’ve mentioned several reasons before, but here are some more. We often perform PCA during the Exploratory Data Analysis (EDA) stage of our data science lifecycle (if we already know what to model, we probably don’t need PCA); it helps us with</p>
<ul>
<li>Visually identifying clusters of similar observations in high dimensions.</li>
<li>Removing irrelevant dimensions if we suspect that the dataset is inherently low rank. For example, if the columns are collinear: there are many attributes but only a few mostly determine the rest through linear associations.</li>
<li>Finding a small basis for representing variations in complex things, e.g., images, genes.</li>
<li>Reducing the number of dimensions to make some computation cheaper.</li>
</ul>
<p>Why do we prefer a 2-dimensional reduction? As we’ve seen, most visualizations are 2D, so it makes the most sense visually.</p>
</section>
<section id="procedural-overview" class="level3" data-number="22.2.3">
<h3 data-number="22.2.3" class="anchored" data-anchor-id="procedural-overview"><span class="header-section-number">22.2.3</span> Procedural Overview</h3>
<p>How do we carry out PCA? Below is an overview, but you are not required to understand or perform PCA this way. We will introduce an easier and more efficient way in a later section.</p>
<p>To do PCA, we</p>
<ol type="1">
<li><p>Center the data matrix by subtracting the mean of each attribute column.</p></li>
<li><p>Find the principal components <span class="math inline">\(v_i\)</span> for <span class="math inline">\(i \in \{1...k\}\)</span>, which fulfills the following criteria:</p>
<ul>
<li><span class="math inline">\(v_i\)</span> is a unit vector that linearly combines the attributes/columns of the data matrix</li>
<li><span class="math inline">\(v_i\)</span> gives a one-dimensional projection of the data</li>
<li><span class="math inline">\(v_i\)</span> is chosen to minimize the sum of squared distances between each point and its projection onto <span class="math inline">\(v_i\)</span>.</li>
<li><span class="math inline">\(v_i\)</span> is orthogonal to all previous principal components.</li>
</ul></li>
</ol>
<p>In practice, we don’t carry out this procedure. Instead, we use singular value decomposition (SVD) to find all principal components efficiently.</p>
</section>
</section>
<section id="singular-value-decomposition" class="level2" data-number="22.3">
<h2 data-number="22.3" class="anchored" data-anchor-id="singular-value-decomposition"><span class="header-section-number">22.3</span> Singular Value Decomposition</h2>
<p>Before getting into Singular Value Decomposition, we need a refresher on linear algebra. In particular, how we can think of matrices as linear transformations.</p>
<section id="matrix-as-transformation" class="level3" data-number="22.3.1">
<h3 data-number="22.3.1" class="anchored" data-anchor-id="matrix-as-transformation"><span class="header-section-number">22.3.1</span> Matrix as Transformation</h3>
<p>Usually when we think about matrix multiplication, we think of it as taking dot product between the rows of the left matrix and the columns of the right matrix.</p>
<p>However, another more linear algebra centric perspective is the columns and transformations view. We’ve briefly used this perspective in the Ordinary Least Squares lecture, but it’s worth mentioning again here. Below is a simple matrix multiplication:</p>
<p><span class="math display">\[
\begin{bmatrix}
{2}&amp;{2}&amp;{2}\\
{5}&amp;{8}&amp;{0}\\
\end{bmatrix}\begin{bmatrix}
{2}&amp;{1}\\
{1}&amp;{1}\\
{4}&amp;{1}\\
\end{bmatrix}=\begin{bmatrix}
{14}&amp;{6}\\
{18}&amp;{13}\\
\end{bmatrix}
\]</span></p>
<p>We can view the operation as taking each column of the left matrix, weight by the corresponding entry in the right matrix:</p>
<p><span class="math display">\[
\begin{bmatrix}
{2}&amp;{2}&amp;{2}\\
{5}&amp;{8}&amp;{0}\\
\end{bmatrix}\begin{bmatrix}
{2}\\
{1}\\
{4}\\
\end{bmatrix}=2\begin{bmatrix}
{2}\\
{5}\\
\end{bmatrix}+1\begin{bmatrix}
{2}\\
{8}\\
\end{bmatrix}+4\begin{bmatrix}
{2}\\
{0}\\
\end{bmatrix}=\begin{bmatrix}
{14}\\
{18}\\
\end{bmatrix}
\]</span></p>
<p>We can think of the left matrix as the original data matrix, and the left matrix as representing a linear transformation. The columns of the left matrix are being transformed according to the rules specified by the right matrix. In this particular example, the right matrix transforms the original data matrix from 3-dimension to 2-dimension.</p>
<p>Understanding this perspective of matrix multiplication is crucial, because PCA does a similar thing: we transform the data matrix by right-multiplying it with a matrix to get the principal components.</p>
<p><img src="images/pca_trans.png" alt="Higher level view of PCA" width="600"></p>
<p>Singular Value Decomposition will help us find this particular transformation matrix.</p>
</section>
<section id="orthonormality-and-diagonal-matrices" class="level3" data-number="22.3.2">
<h3 data-number="22.3.2" class="anchored" data-anchor-id="orthonormality-and-diagonal-matrices"><span class="header-section-number">22.3.2</span> Orthonormality and Diagonal Matrices</h3>
<p>To understand SVD, we need two more concepts from linear algebra: orthonormality and diagonal matrices.</p>
<p>Orthonormal is a portmanteau of two words: orthogonal and normal. The columns of a matrix is said to be <strong>orthonormal</strong> if</p>
<ul>
<li>All the columns are orthogonal to each other. In other words, the dot product between any two columns is 0.</li>
<li>All the columns are unit vectors. In other words, the length each column is 1.</li>
</ul>
<p>Orthonormal matrices have what’s called <em>orthonormal inverses</em>. If an <span class="math inline">\(m \times n\)</span> matrix <span class="math inline">\(Q\)</span> has orthonormal columns, then <span class="math inline">\(QQ^{\top} = I_m\)</span> and <span class="math inline">\(Q^{\top}Q = I_n\)</span>.</p>
<p>Usually, the linear transformation represented by an orthonormal matrix is a <em>rotation</em> (and sometimes a reflection) of the coordinate system.</p>
<p><img src="images/orthonormal.png" alt="Orthonormal matrices as a rotation" width="400"></p>
<p><strong>Diagonal matrices</strong> are square matrices with non-zero values on the diagonal axis and zero everywhere else. Right-multiplied diagonal matrices scale each column up or down by a constant factor.</p>
<p><span class="math display">\[
\begin{bmatrix}
{\mid}&amp;{\mid}&amp;{\mid}\\
{\vec{c}_{1}}&amp;{\vec{c}_{2}}&amp;{\vec{c}_{3}}\\
{\mid}&amp;{\mid}&amp;{\mid}\\
\end{bmatrix}\begin{bmatrix}
{a_{1}}&amp;{0}&amp;{0}\\
{0}&amp;{a_{2}}&amp;{0}\\
{0}&amp;{0}&amp;{a_{3}}\\
\end{bmatrix}=\begin{bmatrix}
{\mid}&amp;{\mid}&amp;{\mid}\\
{a_{1}\vec{c}_{1}}&amp;{a_{2}\vec{c}_{2}}&amp;{a_{3}\vec{c}_{3}}\\
{\mid}&amp;{\mid}&amp;{\mid}\\
\end{bmatrix}
\]</span></p>
<p>Geometrically, the linear transformation represented by a diagonal matrix can be viewed as a <em>scaling</em> of the coordinate system.</p>
<p><img src="images/diagonal.png" alt="Diagonal matrices as a scale" width="500"></p>
</section>
<section id="svd" class="level3" data-number="22.3.3">
<h3 data-number="22.3.3" class="anchored" data-anchor-id="svd"><span class="header-section-number">22.3.3</span> SVD</h3>
<p><strong>Singular value decomposition</strong> (SVD) is an important concept in linear algebra. We will not go much into the theory and details of SVD. Instead, we will only cover what is needed for a data science interpretation.</p>
<p>Singular value decomposition (SVD) describes a matrix decomposition into three matrices. For an <span class="math inline">\(n \times d\)</span> data matrix <span class="math inline">\(X\)</span> with rank <span class="math inline">\(r\)</span>, the SVD says:</p>
<p><span class="math display">\[
\Large
X = U\Sigma V^{\top}
\]</span></p>
<p>The first matrix <span class="math inline">\(U\)</span> has the same shape as <span class="math inline">\(X\)</span>: <span class="math inline">\(n \times d\)</span> and has <strong>orthonormal</strong> columns. Columns of <span class="math inline">\(U\)</span> are called the <strong>left singular vectors</strong>.</p>
<p><span class="math display">\[
\begin{bmatrix}
{\mid}&amp;{\mid}&amp;{}&amp;{\mid}&amp;{\mid}&amp;{}&amp;{\mid}\\
{\vec{u}_{1}}&amp;{\vec{u}_{2}}&amp;{\dots}&amp;{\vec{u}_{r}}&amp;{\vec{u}_{r+1}}&amp;{\dots}&amp;{\vec{u}_{d}}\\
{\mid}&amp;{\mid}&amp;{}&amp;{\mid}&amp;{\mid}&amp;{}&amp;{\mid}\\
\end{bmatrix}
\]</span></p>
<p>Since <span class="math inline">\(U\)</span> is orthonormal, it has an orthonormal inverse: <span class="math inline">\(UU^{\top} = I_{n}\)</span> and <span class="math inline">\(U^{\top}U = I_d\)</span>. We can also view it as a rotation.</p>
<p>The second matrix <span class="math inline">\(\Sigma\)</span> is a <span class="math inline">\(d \times d\)</span> diagonal matrix. Its diagonal contains <strong>singular values</strong>, ordered from greatest to least. If the rank of the matrix <span class="math inline">\(X\)</span> is <span class="math inline">\(r\)</span>, there will be <span class="math inline">\(r\)</span> non-zero singular values.</p>
<p><span class="math display">\[
\begin{bmatrix}
{\sigma_{1}}&amp;{0}&amp;{\dots}&amp;{0}&amp;{0}&amp;{\dots}&amp;{0}\\
{0}&amp;{\sigma_{2}}&amp;{\dots}&amp;{0}&amp;{0}&amp;{\dots}&amp;{0}\\
{\vdots}&amp;{\vdots}&amp;{\ddots}&amp;{\vdots}&amp;{\vdots}&amp;{\ddots}&amp;{\vdots}\\
{0}&amp;{0}&amp;{\dots}&amp;{\sigma_{r}}&amp;{0}&amp;{\dots}&amp;{0}\\
{0}&amp;{0}&amp;{\dots}&amp;{0}&amp;{0}&amp;{\dots}&amp;{0}\\
{\vdots}&amp;{\vdots}&amp;{\ddots}&amp;{\vdots}&amp;{\vdots}&amp;{\ddots}&amp;{\vdots}\\
{0}&amp;{0}&amp;{\dots}&amp;{0}&amp;{0}&amp;{\dots}&amp;{0}\\
\end{bmatrix}
\]</span></p>
<p>The third matrix <span class="math inline">\(V^{\top}\)</span> is a <span class="math inline">\(d \times d\)</span> matrix with orthonormal rows. We call it “transpose” because we are interested in its rows rather than columns. In other words, the rows of <span class="math inline">\(V^{\top}\)</span>, or the columns of <span class="math inline">\(V\)</span>, are orthonormal. The columns of <span class="math inline">\(V\)</span> are called the right singular vectors.</p>
<p><span class="math display">\[
\begin{bmatrix}
{-}&amp;{\vec{v}_{1}^{\top}}&amp;{-}\\
{-}&amp;{\vec{v}_{2}^{\top}}&amp;{-}\\
{}&amp;{\dots}&amp;{}\\
{-}&amp;{\vec{v}_{d}^{\top}}&amp;{-}\\
\end{bmatrix}
\]</span></p>
<p>Similar to <span class="math inline">\(U\)</span>, <span class="math inline">\(V\)</span> is orthonormal, so it has an orthonormal inverse: <span class="math inline">\(VV^{\top} = V^{\top}V = I_{d}\)</span>. We can also view it as a rotation.</p>
</section>
<section id="svd-in-numpy" class="level3" data-number="22.3.4">
<h3 data-number="22.3.4" class="anchored" data-anchor-id="svd-in-numpy"><span class="header-section-number">22.3.4</span> SVD in <code>NumPy</code></h3>
<p>In NumPy, this decomposition algorithm is already written and can be called with <a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html"><code>np.linalg.svd</code></a>. There are many versions of SVD out in the wild, and we will need to set the parameter <code>full_matrices</code> to <code>False</code> to get our version.</p>
</section>
</section>
<section id="pca-with-svd" class="level2" data-number="22.4">
<h2 data-number="22.4" class="anchored" data-anchor-id="pca-with-svd"><span class="header-section-number">22.4</span> PCA with SVD</h2>
<p>Now that we have everything we need to carry out our PCA using the tool SVD.</p>
<p>In a previous section, we mentioned PCA gives us the principal components by linearly transforming the original data matrix. Where does that linear transformation come from? SVD!</p>
<p>Recall that SVD says <span class="math inline">\(X = U\Sigma V^{\top}\)</span>. If we right-multiply both sides by <span class="math inline">\(V\)</span>, we will get</p>
<p><span class="math display">\[
\Large
XV = U\Sigma V^{\top}V = U\Sigma,
\]</span></p>
<p>since <span class="math inline">\(V^{\top}V = I_d\)</span>. Therefore, this <span class="math inline">\(V\)</span> matrix is the transformation we are looking for, and <span class="math inline">\(U\Sigma\)</span> will get us the principal components!</p>
<p>To get the first <span class="math inline">\(k\)</span> principal components, we can simply take the the first <span class="math inline">\(k\)</span> columns of the matrix <span class="math inline">\(U\Sigma\)</span>, or equivalently the matrix <span class="math inline">\(XV\)</span>.</p>
<p>Alternatively, to get the first principal component (often called PC1), we can also take the first left singular vector (i.e.&nbsp;the first column of <span class="math inline">\(U\)</span>) and scale it by the first singular value (i.e.&nbsp;the first diagonal entry in <span class="math inline">\(\Sigma\)</span>).</p>
<p>We can also take the data matrix <span class="math inline">\(X\)</span> and right-multiply it by the first right singular vector (i.e.&nbsp;the first column of <span class="math inline">\(V\)</span>) to get PC1.</p>
<section id="summary" class="level3" data-number="22.4.1">
<h3 data-number="22.4.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">22.4.1</span> Summary</h3>
<p>We finally know how to perform PCA with Singular Value Decomposition. Let’s summarize the procedure. Given an <span class="math inline">\(n \times d\)</span> data matrix <span class="math inline">\(X\)</span>, we get the first <span class="math inline">\(k\)</span> principal components using the following procedure:</p>
<ol type="1">
<li><strong>Center</strong> <span class="math inline">\(X\)</span> by subtracting the mean of each column</li>
<li>Get the <strong>Singular Value Decomposition</strong> of the centered <span class="math inline">\(X\)</span>: <span class="math inline">\(U\)</span>, <span class="math inline">\(\Sigma\)</span>, and <span class="math inline">\(V^{\top}\)</span></li>
<li><strong>Multiply</strong> either <span class="math inline">\(U\Sigma\)</span> or <span class="math inline">\(XV\)</span></li>
<li>Take the <strong>first <span class="math inline">\(k\)</span> columns</strong> of <span class="math inline">\(U\Sigma\)</span> or <span class="math inline">\(XV\)</span>. These are the first <span class="math inline">\(k\)</span> principal components of <span class="math inline">\(X\)</span>.</li>
</ol>
</section>
<section id="pca-in-numpy" class="level3" data-number="22.4.2">
<h3 data-number="22.4.2" class="anchored" data-anchor-id="pca-in-numpy"><span class="header-section-number">22.4.2</span> PCA in <code>NumPy</code></h3>
<p>Let’s see how we can carry out this process using Python! We will load in a dataset containing measurements of rectangles: width, height, area, and perimeter.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">23</span>) <span class="co">#kallisti</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>rectangle <span class="op">=</span> pd.read_csv(<span class="st">"data/rectangle_data.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>rectangle.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">height</th>
<th data-quarto-table-cell-role="th">area</th>
<th data-quarto-table-cell-role="th">perimeter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>8</td>
<td>6</td>
<td>48</td>
<td>28</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>4</td>
<td>8</td>
<td>12</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>3</td>
<td>3</td>
<td>8</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>9</td>
<td>3</td>
<td>27</td>
<td>24</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>9</td>
<td>8</td>
<td>72</td>
<td>34</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We can see this data matrix has rank <span class="math inline">\(3\)</span>, because <code>perimeter</code> is a linear combination of <code>width</code> and <code>height</code>. While we can also get <code>area</code> using <code>width</code> and <code>height</code>, the operation is not linear.</p>
<p>Now let’s carry out PCA.</p>
<section id="step-1-center-the-data-matrix-x" class="level4" data-number="22.4.2.1">
<h4 data-number="22.4.2.1" class="anchored" data-anchor-id="step-1-center-the-data-matrix-x"><span class="header-section-number">22.4.2.1</span> Step 1: Center the data matrix <span class="math inline">\(X\)</span></h4>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>centered_df <span class="op">=</span> rectangle <span class="op">-</span> np.mean(rectangle, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>centered_df.head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">height</th>
<th data-quarto-table-cell-role="th">area</th>
<th data-quarto-table-cell-role="th">perimeter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2.97</td>
<td>1.35</td>
<td>24.78</td>
<td>8.64</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>-3.03</td>
<td>-0.65</td>
<td>-15.22</td>
<td>-7.36</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-4.03</td>
<td>-1.65</td>
<td>-20.22</td>
<td>-11.36</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3.97</td>
<td>-1.65</td>
<td>3.78</td>
<td>4.64</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>3.97</td>
<td>3.35</td>
<td>48.78</td>
<td>14.64</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="step-2-get-the-svd-of-the-centered-x" class="level4" data-number="22.4.2.2">
<h4 data-number="22.4.2.2" class="anchored" data-anchor-id="step-2-get-the-svd-of-the-centered-x"><span class="header-section-number">22.4.2.2</span> Step 2: Get the SVD of the centered <span class="math inline">\(X\)</span></h4>
<p>Note, we will need to set the <code>full_matrices</code> argument to <code>False</code>.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>U, S, Vt <span class="op">=</span> np.linalg.svd(centered_df, full_matrices <span class="op">=</span> <span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s inspect these three matrices first.</p>
<p>The first 5 rows of <span class="math inline">\(U\)</span>:</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(U).head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-0.133910</td>
<td>0.005930</td>
<td>0.034734</td>
<td>-0.296836</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.086354</td>
<td>-0.079515</td>
<td>0.014948</td>
<td>0.711478</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.117766</td>
<td>-0.128963</td>
<td>0.085774</td>
<td>-0.065318</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>-0.027274</td>
<td>0.183177</td>
<td>0.010895</td>
<td>-0.031055</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.258806</td>
<td>-0.094295</td>
<td>0.090270</td>
<td>-0.032818</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><span class="math inline">\(\Sigma\)</span> is returned as an array, because most of the values in the diagonal matrices are zero. <code>NumPy</code> only returns the singular values to save memory.</p>
<p>We can see there are only three non-zero singular values, confirming our previous judgment that the rank of <span class="math inline">\(X\)</span> is 3.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">round</span>(S)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>array([197.,  27.,  23.,   0.])</code></pre>
</div>
</div>
<p>To get <span class="math inline">\(\Sigma\)</span> into its matrix form, we can use <code>np.diag</code>:</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(np.diag(np.<span class="bu">round</span>(S, <span class="dv">1</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>197.4</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.0</td>
<td>27.4</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.0</td>
<td>0.0</td>
<td>23.3</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Finally, <span class="math inline">\(V^{\top}\)</span>:</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(Vt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-0.098631</td>
<td>-0.072956</td>
<td>-0.931226</td>
<td>-0.343173</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.668460</td>
<td>-0.374186</td>
<td>-0.258375</td>
<td>0.588548</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.314625</td>
<td>-0.640483</td>
<td>0.257023</td>
<td>-0.651715</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.666667</td>
<td>0.666667</td>
<td>0.000000</td>
<td>-0.333333</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="step-3-multiply-either-usigma-or-xv" class="level4" data-number="22.4.2.3">
<h4 data-number="22.4.2.3" class="anchored" data-anchor-id="step-3-multiply-either-usigma-or-xv"><span class="header-section-number">22.4.2.3</span> Step 3: Multiply either <span class="math inline">\(U\Sigma\)</span> or <span class="math inline">\(XV\)</span></h4>
<p>To carry out matrix multiplication in <code>NumPy</code>, we use the <code>@</code> symbol.</p>
<p>Let’s try <span class="math inline">\(U\Sigma\)</span> first</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(U <span class="op">@</span> np.diag(S)).head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-26.432217</td>
<td>0.162686</td>
<td>0.807998</td>
<td>-2.738093e-15</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>17.045285</td>
<td>-2.181451</td>
<td>0.347732</td>
<td>6.562857e-15</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>23.245695</td>
<td>-3.538040</td>
<td>1.995334</td>
<td>-6.025133e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>-5.383546</td>
<td>5.025395</td>
<td>0.253448</td>
<td>-2.864630e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-51.085217</td>
<td>-2.586948</td>
<td>2.099919</td>
<td>-3.027184e-16</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Then <span class="math inline">\(XV\)</span>:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(centered_df <span class="op">@</span> Vt.T).head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-26.432217</td>
<td>0.162686</td>
<td>0.807998</td>
<td>-2.978358e-15</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>17.045285</td>
<td>-2.181451</td>
<td>0.347732</td>
<td>1.462534e-15</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>23.245695</td>
<td>-3.538040</td>
<td>1.995334</td>
<td>2.350712e-15</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>-5.383546</td>
<td>5.025395</td>
<td>0.253448</td>
<td>-1.868135e-15</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-51.085217</td>
<td>-2.586948</td>
<td>2.099919</td>
<td>-4.088581e-15</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We can see these are exactly the same.</p>
</section>
<section id="step-4-get-the-first-k-columns" class="level4" data-number="22.4.2.4">
<h4 data-number="22.4.2.4" class="anchored" data-anchor-id="step-4-get-the-first-k-columns"><span class="header-section-number">22.4.2.4</span> Step 4: Get the first <span class="math inline">\(k\)</span> columns</h4>
<p>Let’s get the first two principal components of <span class="math inline">\(X\)</span>.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>two_PCs <span class="op">=</span> (U <span class="op">@</span> np.diag(S))[:, :<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(two_PCs).head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-26.432217</td>
<td>0.162686</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>17.045285</td>
<td>-2.181451</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>23.245695</td>
<td>-3.538040</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>-5.383546</td>
<td>5.025395</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-51.085217</td>
<td>-2.586948</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We can get the same thing using <span class="math inline">\(XV\)</span>:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>(centered_df <span class="op">@</span> Vt.T).iloc[:, :<span class="dv">2</span>].head(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-26.432217</td>
<td>0.162686</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>17.045285</td>
<td>-2.181451</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>23.245695</td>
<td>-3.538040</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>-5.383546</td>
<td>5.025395</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-51.085217</td>
<td>-2.586948</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
</section>
<section id="data-variance-and-centering" class="level2" data-number="22.5">
<h2 data-number="22.5" class="anchored" data-anchor-id="data-variance-and-centering"><span class="header-section-number">22.5</span> Data Variance and Centering</h2>
<section id="variance-with-singular-values" class="level3" data-number="22.5.1">
<h3 data-number="22.5.1" class="anchored" data-anchor-id="variance-with-singular-values"><span class="header-section-number">22.5.1</span> Variance with Singular Values</h3>
<p>We said earlier that PCA gives us a projection that captures the most variance. How do we know how much variance is captured?</p>
<p>It turns out the <strong>singular values</strong> tell us this!</p>
<p>Formally, the <span class="math inline">\(i\)</span>-th singular value tells us the <strong>component score</strong>—how much of the data variance is captured by the <span class="math inline">\(i\)</span>th principal component. Suppose the number of data points is <span class="math inline">\(n\)</span>:</p>
<p><span class="math display">\[i\text{-th component score} = \frac{(i\text{-th singular value})^2}{n}\]</span></p>
<p>Summing up the component scores is equivalent to computing the total variance.</p>
</section>
<section id="centering" class="level3" data-number="22.5.2">
<h3 data-number="22.5.2" class="anchored" data-anchor-id="centering"><span class="header-section-number">22.5.2</span> Centering</h3>
<p>You might have noticed that we always center our data matrix <span class="math inline">\(X\)</span> before performing PCA. We do this because only when we center the matrix will we have this nice interpretation of the singular values. In other words, if we don’t center the data matrix, singular values will not convert nicely to the component scores/variances captured by each principal component.</p>
<p>The formal proof of this is out of scope, but if you are interested, take a look at the next section.</p>
</section>
<section id="bonus-proof-of-component-score" class="level3" data-number="22.5.3">
<h3 data-number="22.5.3" class="anchored" data-anchor-id="bonus-proof-of-component-score"><span class="header-section-number">22.5.3</span> (Bonus) Proof of component score</h3>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to show
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof defining component score out of scope for this class, but it is included below for your convenience.</p>
<p><em>Setup</em>: Consider the design matrix <span class="math inline">\(X \in \mathbb{R}^{n \times d}\)</span>, where the <span class="math inline">\(j\)</span>-th column (corresponding to the <span class="math inline">\(j\)</span>-th feature) is <span class="math inline">\(x_j \in \mathbb{R}^n\)</span> and the element in row <span class="math inline">\(i\)</span>, column <span class="math inline">\(j\)</span> is <span class="math inline">\(x_{ij}\)</span>. Further define <span class="math inline">\(\tilde{X}\)</span> as the <strong>centered</strong> design matrix. The <span class="math inline">\(j\)</span>-th column is <span class="math inline">\(\tilde{x}_j \in \mathbb{R}^n\)</span> and the element in row <span class="math inline">\(i\)</span>, column <span class="math inline">\(j\)</span> is <span class="math inline">\(\tilde{x}_{ij} = x_{ij} - \bar{x_j}\)</span>, where <span class="math inline">\(\bar{x_j}\)</span> is the mean of the <span class="math inline">\(x_j\)</span> column vector from the original <span class="math inline">\(X\)</span>.</p>
<p><em>Variance</em>: Construct the <strong>covariance matrix</strong>: <span class="math inline">\(\frac{1}{n} \tilde{X}^T \tilde{X} \in \mathbb{R}^{d \times d}\)</span>. The <span class="math inline">\(j\)</span>-th element along the diagonal is the <strong>variance</strong> of the <span class="math inline">\(j\)</span>-th column of the original design matrix <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[\left( \frac{1}{n} \tilde{X}^T \tilde{X} \right)_{jj} = \frac{1}{n} \tilde{x}_j ^T \tilde{x}_j = \frac{1}{n} \sum_{i=i}^n (\tilde{x}_{ij} )^2 = \frac{1}{n} \sum_{i=i}^n (x_{ij} - \bar{x_j})^2\]</span></p>
<p><em>SVD</em>: Suppose singular value decomposition of the <em>centered</em> design matrix <span class="math inline">\(\tilde{X}\)</span> yields <span class="math inline">\(\tilde{X} = U \Sigma V^T\)</span>, where <span class="math inline">\(U \in \mathbb{R}^{n \times d}\)</span> and <span class="math inline">\(V \in \mathbb{R}^{d \times d}\)</span> are matrices with orthonormal columns, and <span class="math inline">\(\Sigma \in \mathbb{R}^{d \times d}\)</span> is a diagonal matrix with singular values of <span class="math inline">\(\tilde{X}\)</span>.</p>
<p><span class="math display">\[\begin{aligned}
\tilde{X}^T \tilde{X} &amp;= (U \Sigma V^T )^T (U \Sigma V^T) \\
&amp;= V \Sigma U^T U \Sigma V^T  &amp; (\Sigma^T = \Sigma) \\
&amp;= V \Sigma^2 V^T &amp; (U^T U = I) \\
\frac{1}{n} \tilde{X}^T \tilde{X} &amp;= \frac{1}{n} V \Sigma V^T =V \left( \frac{1}{n} \Sigma \right) V^T \\
\frac{1}{n} \tilde{X}^T \tilde{X} V &amp;= V \left( \frac{1}{n} \Sigma \right) V^T V = V \left( \frac{1}{n} \Sigma \right) &amp; \text{(right multiply by }V \rightarrow V^T V = I \text{)} \\
V^T \frac{1}{n} \tilde{X}^T \tilde{X} V &amp;= V^T V \left( \frac{1}{n} \Sigma \right) = \frac{1}{n} \Sigma &amp; \text{(left multiply by }V^T \rightarrow V^T V = I \text{)} \\
\left( \frac{1}{n} \tilde{X}^T \tilde{X} \right)_{jj} &amp;= \frac{1}{n}\sigma_j^2  &amp; \text{(Define }\sigma_j\text{ as the} j\text{-th singular value)} \\
\frac{1}{n} \sigma_j^2 &amp;= \frac{1}{n} \sum_{i=i}^n (x_{ij} - \bar{x_j})^2
\end{aligned}\]</span></p>
<p>The last line defines the <span class="math inline">\(j\)</span>-th component score.</p>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sql_II/sql_II.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">SQL II</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../pca_2/pca_2.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">PCA II</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>