<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Principles and Techniques of Data Science - 19&nbsp; Logistic Regression II</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sql_I/sql_I.html" rel="next">
<link href="../logistic_regression_1/logistic_reg_1.html" rel="prev">
<link href="../data100_logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../logistic_regression_2/logistic_reg_2.html"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Logistic Regression II</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../data100_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Principles and Techniques of Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/DS-100/course-notes-su23" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_lec/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_1/pandas_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Pandas I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_2/pandas_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Pandas II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_3/pandas_3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pandas III</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../eda/eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Cleaning and EDA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regex/regex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Text Wrangling and Regular Expressions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../visualization_1/visualization_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Visualization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling/sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_to_modeling/intro_to_modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../constant_model_loss_transformations/loss_transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Constant Model, Loss, and Transformations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ols/ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../gradient_descent/gradient_descent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../feature_engineering/feature_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Sklearn and Feature Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../case_study_HCE/case_study_HCE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Case Study in Human Contexts and Ethics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cv_regularization/cv_reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Cross Validation and Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_1/probability_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_2/probability_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Bias, Variance, and Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_1/logistic_reg_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_2/logistic_reg_2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Logistic Regression II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_I/sql_I.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">SQL I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sql_II/sql_II.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">SQL II</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_1/pca_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">PCA I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pca_2/pca_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">PCA II</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#decision-boundaries" id="toc-decision-boundaries" class="nav-link active" data-scroll-target="#decision-boundaries"><span class="header-section-number">19.1</span> Decision Boundaries</a></li>
  <li><a href="#linear-separability" id="toc-linear-separability" class="nav-link" data-scroll-target="#linear-separability"><span class="header-section-number">19.2</span> Linear Separability</a>
  <ul>
  <li><a href="#defining-separability" id="toc-defining-separability" class="nav-link" data-scroll-target="#defining-separability"><span class="header-section-number">19.2.1</span> Defining Separability</a></li>
  <li><a href="#the-need-for-regularization" id="toc-the-need-for-regularization" class="nav-link" data-scroll-target="#the-need-for-regularization"><span class="header-section-number">19.2.2</span> The Need for Regularization</a></li>
  </ul></li>
  <li><a href="#performance-metrics" id="toc-performance-metrics" class="nav-link" data-scroll-target="#performance-metrics"><span class="header-section-number">19.3</span> Performance Metrics</a>
  <ul>
  <li><a href="#accuracy" id="toc-accuracy" class="nav-link" data-scroll-target="#accuracy"><span class="header-section-number">19.3.1</span> Accuracy</a></li>
  <li><a href="#classification-types" id="toc-classification-types" class="nav-link" data-scroll-target="#classification-types"><span class="header-section-number">19.3.2</span> Classification Types</a></li>
  <li><a href="#precision-and-recall" id="toc-precision-and-recall" class="nav-link" data-scroll-target="#precision-and-recall"><span class="header-section-number">19.3.3</span> Precision and Recall</a></li>
  <li><a href="#false-positive-rates-and-true-positive-rates" id="toc-false-positive-rates-and-true-positive-rates" class="nav-link" data-scroll-target="#false-positive-rates-and-true-positive-rates"><span class="header-section-number">19.3.4</span> False Positive Rates and True Positive Rates</a></li>
  </ul></li>
  <li><a href="#changing-the-classification-threshold" id="toc-changing-the-classification-threshold" class="nav-link" data-scroll-target="#changing-the-classification-threshold"><span class="header-section-number">19.4</span> Changing the Classification Threshold</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Logistic Regression II</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Outcomes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Apply decision rules to classify data</li>
<li>Recognize the need to regularize when working with linearly separable data</li>
<li>Compute performance metrics to quantify the quality of a classifier</li>
</ul>
</div>
</div>
</div>
<p>In the previous lecture, we made our way through the beginnings of the classification process. We reframed our understanding of the modeling process in terms of <em>predicted probabilities</em>. We then derived the logistic regression model to predict the probability of a datapoint belonging to Class 1, given inputted features.</p>
<p>In this lecture, we’ll address the second phase of a classification task: applying a decision rule to interpret these predicted probabilities and classify a datapoint. We’ll also explore metrics to assess the performance of our classifiers on real-world data.</p>
<p><img src="images/workflow.png" alt="classification workflow" width="750"></p>
<section id="decision-boundaries" class="level2" data-number="19.1">
<h2 data-number="19.1" class="anchored" data-anchor-id="decision-boundaries"><span class="header-section-number">19.1</span> Decision Boundaries</h2>
<p>To classify a datapoint as Class 1 or Class 0, we need to interpret the predicted probability outputted by our logistic regression model. We’ll do so by applying a <strong>decision rule</strong>: a rule that tells us, given a predicted probability <span class="math inline">\(p\)</span>, if we should predict <span class="math inline">\(\hat{Y}=1\)</span> or <span class="math inline">\(\hat{Y}=0\)</span>.</p>
<p>Decision rules are commonly implemented by defining a <strong>threshold</strong>. If the predicted probability is equal to or greater than the threshold value <span class="math inline">\(T\)</span>, we classify the datapoint into Class 1. Otherwise, we classify the datapoint into Class 0.</p>
<p><span class="math display">\[\hat{Y} = \text{classify}(x) = \begin{cases}
  \text{Class 1}  &amp; p \geq T \\
  \text{Class 0} &amp; p &lt; T
\end{cases}\]</span></p>
<p>The threshold <span class="math inline">\(T\)</span> is often 0.5, but not always. We’ll explore why we may apply different threshold values later this lecture.</p>
<p>Let’s try applying a threshold of <span class="math inline">\(T=0.5\)</span> to a logistic regression model fitted to our <code>games</code> data. As before, we will attempt to predict the outcome of a game (win or lose) given the <code>"GOAL_DIFF"</code> between teams.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>games <span class="op">=</span> pd.read_csv(<span class="st">"data/games"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> games[[<span class="st">"GOAL_DIFF"</span>]]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> games[<span class="st">"WON"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can create a logistic regression model in <code>sklearn</code> using the <code>LogisticRegression</code> class. It works very similarly to <code>LinearRegression</code>: we will initialize a model object, fit it, then use it to make predictions. Because we want to determine the <em>probabilities</em> predicted by our model, we will use the <code>.predict_proba()</code> method.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.linear_model <span class="im">as</span> lm</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a LogisticRegression object</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> lm.LogisticRegression()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model to the data</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>model.fit(X, Y)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities. We display only the first 5 rows for clarity</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>model.predict_proba(X)[:<span class="dv">5</span>, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>array([[0.9521269 , 0.0478731 ],
       [0.94399293, 0.05600707],
       [0.94208808, 0.05791192],
       [0.94208808, 0.05791192],
       [0.93384531, 0.06615469]])</code></pre>
</div>
</div>
<p>What’s going on here – why did we output a 2D array? By default, <code>.predict_proba()</code> will produce the predicted probability of a datapoint belonging to Class 0 <em>as well as</em> the probability of it belonging to Class 1. Notice that each row in the output above sums to 1.</p>
<p>To check which column represents which probability, we can call the <code>.classes_</code> attribute. The output below tells us that the first column of <code>.predict_proba()</code> represents the probability of belonging to Class 0, while the second column is the probability of belonging to Class 1.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model.classes_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>array([0, 1])</code></pre>
</div>
</div>
<p>Let’s grab just the predicted probabilities of each datapoint belonging to Class 1: <span class="math inline">\(p=P(Y=1|x)\)</span>.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> model.predict_proba(X)[:, <span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To categorize our datapoints into classes, we need to apply our decision rule. Recall that we are using a threshold of <span class="math inline">\(T=0.5\)</span>: this means that if the predicted probability for a datapoint is equal to or greater than <span class="math inline">\(0.5\)</span>, we’ll classify that point into Class 1.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># .astype(int) converts True and False to 1 and 0</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>(p <span class="op">&gt;=</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>array([0, 0, 0, ..., 1, 1, 1])</code></pre>
</div>
</div>
<p>Alternatively, the <code>.predict()</code> method of <code>LogisticRegression</code> will automatically apply a <span class="math inline">\(T=0.5\)</span> threshold for us.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> model.predict(X)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>games[<span class="st">"Predicted Class"</span>] <span class="op">=</span> classes</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize our results</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>z))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>sns.stripplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, y<span class="op">=</span><span class="st">"WON"</span>, hue<span class="op">=</span><span class="st">"Predicted Class"</span>, orient<span class="op">=</span><span class="st">"h"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.plot(x, sigmoid(model.intercept_ <span class="op">+</span> model.coef_[<span class="dv">0</span>]<span class="op">*</span>x), <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"P(Y=1|x)"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-8-output-1.png" width="576" height="429"></p>
</div>
</div>
<p>In the cell above, we color each datapoint according to the class predicted by our model. We have also superimposed the fitted logistic regression curve.</p>
<p>Let’s break down what’s going on here. We said that any datapoint with a predicted probability equal to or greater than <span class="math inline">\(0.5\)</span> should be categorized into Class 1. Equivalently, we can express this by saying:</p>
<ol type="1">
<li>Determine the value of our input feature, <code>"GOAL_DIFF"</code>, that leads to a predicted probability of exactly 0.5</li>
<li>Look at the value of the input feature for each individual datapoint. If the input feature is <em>greater</em> in value than the critical value where the predicted probability is <span class="math inline">\(0.5\)</span>, predict Class 1. Otherwise, predict Class 0</li>
</ol>
<center>
<img src="images/db.png" alt="decision boundary" width="550">
</center>
<p>Because we are now looking at the <em>features</em> of a datapoint when deciding which class to predict, it makes more sense to display only this input data. We do so by using a rugplot, which visualizes scatter points when we only have one variable.</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the decision boundary</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>theta0 <span class="op">=</span> model.intercept_</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>theta1 <span class="op">=</span> model.coef_[<span class="dv">0</span>]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>theta1)<span class="op">*</span>(<span class="op">-</span>np.log(<span class="dv">1</span><span class="op">/</span>T <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> theta0)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the classified data</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>sns.rugplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, hue<span class="op">=</span><span class="st">"Predicted Class"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=</span>[db], y<span class="op">=</span>[<span class="fl">0.005</span>], c<span class="op">=</span><span class="st">"k"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="fl">0.1</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>plt.yticks([], [])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-9-output-1.png" width="544" height="429"></p>
</div>
</div>
<p>We have just uncovered our first example of a <strong>decision boundary</strong>. A decision boundary is a “line” that splits the data into classes based on its features. In the example above, the point marked in black is our decision boundary: we classify all datapoints to the right of the decision boundary as being Class 1, and all points to the left as being Class 0.</p>
<p>Why did we place “line” in quotes earlier? More formally, a decision boundary is a <strong>hyperplane</strong>: a linear combination of our model’s <span class="math inline">\(p\)</span> features, expressed in <span class="math inline">\(p\)</span> dimensions. In the example above, we had a model with one feature, so our decision boundary is a 1-dimensional point. If we had two features, our decision boundary would be a 2-dimensional line. Similarly, for a model with <span class="math inline">\(p\)</span> features, our decision boundary is a hyperplane in <span class="math inline">\(p\)</span> dimensions.</p>
<p>Let’s consider the decision boundary of a model with an intercept term and <em>two</em> features – <code>"GOAL_DIFF"</code> and <code>"AST"</code>, which stands for the number of assists in a basketball game. Our logistic regression model for the probability of a team winning looks like:</p>
<p><span class="math display">\[p=\frac{1}{1+e^{-(\theta_0+\theta_1\text{GOAL\_DIFF}+\theta_2\text{AST})}}\]</span></p>
<p>The decision boundary represents all combinations of feature values that result in a predicted probability <em>exactly</em> equal to our threshold, <span class="math inline">\(T\)</span>. We can use this fact to derive the equation of our decision boundary hyperplane.</p>
<p><span class="math display">\[T=\frac{1}{1+e^{-(\theta_0+\theta_1\text{GOAL\_DIFF}+\theta_2\text{AST})}}\]</span> <span class="math display">\[\theta_0+\theta_1\text{GOAL\_DIFF}+\theta_2\text{AST} = -\log{(\frac{1}{T}-1)}\]</span></p>
<p>In the cell below, we plot the classifications made by our decision rule when <span class="math inline">\(T=0.5\)</span>. Notice that we are visualizing the decision boundary in terms of the <em>features</em> – we do not express boundaries in terms of <span class="math inline">\(Y\)</span>!</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X_two_feature <span class="op">=</span> games[[<span class="st">"GOAL_DIFF"</span>, <span class="st">"AST"</span>]]</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> games[<span class="st">"WON"</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>two_feature_model <span class="op">=</span> lm.LogisticRegression()</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>two_feature_model.fit(X_two_feature, Y)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># This function plots the decision boundary such that AST is a function of GOAL_DIFF</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>theta0 <span class="op">=</span> two_feature_model.intercept_</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>theta1, theta2 <span class="op">=</span> two_feature_model.coef_[<span class="dv">0</span>]</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="kw">lambda</span> goal_diff: (<span class="dv">1</span><span class="op">/</span>theta2)<span class="op">*</span>(<span class="op">-</span>np.log(<span class="dv">1</span><span class="op">/</span>T <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> theta1<span class="op">*</span>goal_diff <span class="op">-</span> theta0)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>games[<span class="st">"Predicted Class Two Features"</span>] <span class="op">=</span> two_feature_model.predict(X_two_feature)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, y<span class="op">=</span><span class="st">"AST"</span>, hue<span class="op">=</span><span class="st">"Predicted Class Two Features"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>plt.plot(x, db(x), <span class="st">"k"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-10-output-1.png" width="596" height="429"></p>
</div>
</div>
</section>
<section id="linear-separability" class="level2" data-number="19.2">
<h2 data-number="19.2" class="anchored" data-anchor-id="linear-separability"><span class="header-section-number">19.2</span> Linear Separability</h2>
<section id="defining-separability" class="level3" data-number="19.2.1">
<h3 data-number="19.2.1" class="anchored" data-anchor-id="defining-separability"><span class="header-section-number">19.2.1</span> Defining Separability</h3>
<p>Let’s see how well our decision boundary separates the data into classes. In the cell below, we overlay the decision boundary on top of the <em>true</em> classes of the dataset.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, y<span class="op">=</span><span class="st">"AST"</span>, hue<span class="op">=</span><span class="st">"WON"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x, db(x), <span class="st">"k"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-11-output-1.png" width="596" height="429"></p>
</div>
</div>
<p>It turns out that our decision boundary doesn’t always get things “right.” Far away from the decision boundary, we see that most points are classified correctly. Closer to the hyperplane, however, there is a “muddled” region where some points with <span class="math inline">\(Y=1\)</span> sit to the left of the boundary, and some points with <span class="math inline">\(Y=0\)</span> sit to the right of the boundary.</p>
<p>This begs the question: in what situations can our classifier behave perfectly? That is, what does our data have to look like for us to be able to create a classifier that perfectly classifies all datapoints into the correct class?</p>
<p>A dataset is said to be <strong>linearly separable</strong> if there exists a hyperplane among the input features <span class="math inline">\(x\)</span> that <em>perfectly</em> separates the two classes <span class="math inline">\(Y\)</span>. Put more practically: we say that a dataset is linearly separable if we can draw a straight line, in terms of the features, that splits the two classes.</p>
<center>
<img src="images/separable.png" alt="linear separability" width="600">
</center>
</section>
<section id="the-need-for-regularization" class="level3" data-number="19.2.2">
<h3 data-number="19.2.2" class="anchored" data-anchor-id="the-need-for-regularization"><span class="header-section-number">19.2.2</span> The Need for Regularization</h3>
<p>When a dataset is linearly separable, we can create a classifier that perfectly separates the datapoints into classes.</p>
<p>If our classifier makes perfect classifications, does it also achieve 0 cross-entropy loss? To answer this question, consider the conditions under which cross-entropy loss approaches 0.</p>
<p><span class="math display">\[\text{Cross-Entropy Loss} = -\left(y\log{(p)}-(1-y)\log{(1-p)}\right)\]</span></p>
<p>For a single datapoint, cross-entropy loss is 0 if <span class="math inline">\(y=p\)</span>. That is:</p>
<ul>
<li>When the true class is 1, we incur zero loss if the model predicts a 100% probability of the datapoint belonging to Class 1</li>
<li>When the true class is 0, we incur zero loss of the model predicts a 0% probability of the datapoint belonging to Class 1</li>
</ul>
<p>When can our logistic regression model output predicted probabilities of exactly 0 or 1?</p>
<p><span class="math display">\[p=P(Y=1|x)=\frac{1}{1+e^{-x^{\top} \theta}}\]</span></p>
<p>When <span class="math inline">\(\theta \rightarrow \infty\)</span>, <span class="math inline">\(p \rightarrow 1\)</span>. Likewise, when <span class="math inline">\(\theta \rightarrow -\infty\)</span>, <span class="math inline">\(p \rightarrow 0\)</span>. Take a moment to examine the logistic regression model and convince yourself of these facts.</p>
<p>When our data is linearly separable, we run into the problem of <strong>diverging</strong> model parameters: the “optimal” parameters for the model approach positive or negative infinity. This can be a problem for a few reasons (beyond the fact that we can’t practically “plug” <span class="math inline">\(\infty\)</span> into our model to make predictions).</p>
<p>Consider an artificially-generated “toy” dataset of two datapoints.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>toy_df <span class="op">=</span> pd.DataFrame({<span class="st">"x"</span>: [<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], <span class="st">"y"</span>: [<span class="dv">0</span>, <span class="dv">1</span>]})</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>toy_df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">"y"</span>, s<span class="op">=</span><span class="dv">100</span>, legend<span class="op">=</span><span class="va">None</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-12-output-1.png" width="589" height="429"></p>
</div>
</div>
<p>If we fit a logistic regression model with one feature to this data, we find a strange-looking cross-entropy loss surface.</p>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> toy_model(theta1, x):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>theta1 <span class="op">*</span> x))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_cross_entropy_loss_toy(theta1):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Here we use 1 - sigma(z) = sigma(-z) to improve numerical stability</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span> np.<span class="bu">sum</span>(toy_df[<span class="st">'y'</span>] <span class="op">*</span> np.log(toy_model(theta1, toy_df[<span class="st">'x'</span>])) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span><span class="op">-</span>toy_df[<span class="st">'y'</span>]) <span class="op">*</span> np.log(toy_model(theta1, <span class="op">-</span>toy_df[<span class="st">'x'</span>])))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>thetas <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">30</span>, <span class="dv">30</span>, <span class="dv">100</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> [mean_cross_entropy_loss_toy(theta) <span class="cf">for</span> theta <span class="kw">in</span> thetas]</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.plot(thetas, losses, color <span class="op">=</span> <span class="st">'green'</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r'Mean Cross Entropy Loss($\theta$)'</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r'$\theta$'</span>)<span class="op">;</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Mean Cross Entropy Loss Surface"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-13-output-1.png" width="587" height="449"></p>
</div>
</div>
<p>Though it’s difficult to see with the human eye, the “plateau” at large values of <span class="math inline">\(\theta\)</span> is very slightly tilted downwards. We can confirm this by examining a few values for the mean cross-entropy loss. Notice that each loss is very slightly smaller than the preceding loss value.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>losses[<span class="op">-</span><span class="dv">5</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>[2.1134205496775648e-12,
 1.1528555887710948e-12,
 6.288303211477875e-13,
 3.432809592141279e-13,
 1.869615573468851e-13]</code></pre>
</div>
</div>
<p>This means that if we were to use gradient descent to optimize the model parameter <span class="math inline">\(\theta\)</span>, our gradient descent algorithm would never converge. It would continue to follow this slope “downwards” in an ongoing attempt to reduce the mean cross-entropy loss.</p>
<p>What’s more, a model fitted with diverging parameters is <strong>overconfident</strong>. As a thought experiment, say we were somehow able to fit a model to our toy dataset with <span class="math inline">\(\theta=\infty\)</span>. If we ran our model on a new datapoint <span class="math inline">\((x=-0.5, y=1)\)</span>, the model would predict <span class="math inline">\(p=\frac{1}{1+e^{-\infty(-0.5)}}=0\)</span>. The cross-entropy loss on this new datapoint would be <span class="math inline">\(-\left((1)\log{(0)}-(1-1)\log{(1-0)}\right)=\infty\)</span>. In other words, our model would make such a poor prediction that it would incur <em>infinite</em> loss!</p>
<p>To avoid the problem of diverging model parameters, we always <em>regularize</em> logistic regression models. This constrains the magnitude of the parameters. Fortunately, <code>sklearn</code> automatically applies regularization when creating a <code>LogisticRegression</code> model.</p>
</section>
</section>
<section id="performance-metrics" class="level2" data-number="19.3">
<h2 data-number="19.3" class="anchored" data-anchor-id="performance-metrics"><span class="header-section-number">19.3</span> Performance Metrics</h2>
<p>We’re in good shape: we’ve drived the logistic regression model to predict probabilities, and we’ve now introduced the idea of a decision rule to help us classify data into categories.</p>
<p>To help quantify how “well” or “poorly” our model is doing, we’ll introduce a set of classification <strong>performance metrics</strong>. You may wonder: why do we need any new metrics of performance? Don’t we already have cross-entropy loss? Recall that cross-entropy loss deals with the predicted probabilities outputted by the sigmoid curve. In practice, we are usually more interested in whether or not our model <em>classifies</em> the data appropriately – determining if each point should belong to Class 0 or 1 – rather than the precide probabilities it predicts.</p>
<section id="accuracy" class="level3" data-number="19.3.1">
<h3 data-number="19.3.1" class="anchored" data-anchor-id="accuracy"><span class="header-section-number">19.3.1</span> Accuracy</h3>
<p>The most basic evaluation metric is <strong>accuracy</strong>: the proportion of correctly classified points.</p>
<p><span class="math display">\[\text{accuracy} = \frac{\# \text{ of points classified correctly}}{\# \text{ of total points}}\]</span></p>
<p>Because we are working with binary labels of 0 or 1, computing the accuracy is equivalent to finding the average number of times our model makes a correct classification.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>Y_hat <span class="op">=</span> model.predict(X)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> np.mean(Y<span class="op">==</span>Y_hat)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>0.7943089430894309</code></pre>
</div>
</div>
<p>Alternatively, we can use the built-in <code>.score()</code> method from <code>sklearn</code> to compute the accuracy.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>model.score(X, Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>0.7943089430894309</code></pre>
</div>
</div>
<p>Although accuracy is a very intuitive way of quantifying performance, it does come with drawbacks. Accuracy often misrepresents how well our model performs when there is <strong>class imbalance</strong> – that is, when there are signficantly more datapoints belonging to Class 1 than to Class 0, or vice-versa.</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pitfalls of Accuracy: A Case Study
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Suppose you are trying to classify emails as spam (1) or ham (0). Your friend (feeling a little lazy) decides to create a classifier that <em>always</em> predicts <span class="math inline">\(\hat{Y}=0\)</span>. Regardless of the inputted datapoint, your friend will always predict Class 0 (ham).</p>
<p>You obtain a dataset of 100 emails, of which 95 are ham and 5 are spam.</p>
<p>By predicting that all 100 emails are truly ham, your friend’s classifier makes 95 correct predictions and 5 incorrect predictions. That means that the accuracy of their classifier is 0.95!</p>
<p>On the surface, this seems like great performance. However, because there was imbalance in the two classes, the accuracy of the classifier is not a great indicator of how well it performs. In reality, your friend’s classifier failed to identify <em>any</em> of the spam emails.</p>
</div>
</div>
</div>
</section>
<section id="classification-types" class="level3" data-number="19.3.2">
<h3 data-number="19.3.2" class="anchored" data-anchor-id="classification-types"><span class="header-section-number">19.3.2</span> Classification Types</h3>
<p>To help us derive new performance metrics that perform better in the presence of class imbalance, let’s take a moment to reflect on what “types” of classifications a model might make. There are four outcomes of any binary classification:</p>
<ul>
<li><strong>True positive:</strong> the classifier correctly classifies a Class 1 datapoint as being Class 1 (<span class="math inline">\(Y=1, \hat{Y}=1\)</span>)</li>
<li><strong>True negative:</strong> the classifier correctly classifies a Class 0 datapoint as being Class 0 (<span class="math inline">\(Y=0, \hat{Y}=0\)</span>)</li>
<li><strong>False positive:</strong> the classifier incorrectly classifies a Class 0 datapoint as being Class 1 (<span class="math inline">\(Y=0, \hat{Y}=1\)</span>)</li>
<li><strong>False negative:</strong> the classifier incorrectly classifies a Class 1 datapoint as being Class 0 (<span class="math inline">\(Y=1, \hat{Y}=0\)</span>)</li>
</ul>
<p>That was a lot of words. It is often easier to express the different types of classifications visually using a <strong>confusion matrix</strong>.</p>
<center>
<img src="images/confusion.png" alt="confusion matrix" width="500">
</center>
<p>One way to remember this terminology is as follows:</p>
<ol type="1">
<li>Look at the second word in the phrase. <em>Positive</em> means a prediction of 1. <em>Negative</em> means a prediction of 0.</li>
<li>Look at the first word in the phrase. <em>True</em> means our prediction was correct. <em>False</em> means it was incorrect.</li>
</ol>
</section>
<section id="precision-and-recall" class="level3" data-number="19.3.3">
<h3 data-number="19.3.3" class="anchored" data-anchor-id="precision-and-recall"><span class="header-section-number">19.3.3</span> Precision and Recall</h3>
<p>With our understanding of possible classifications in hand, let’s define two new performance metrics.</p>
<p><strong>Precision</strong> asks: of all the positive (Class 1) predictions made by the classifier, how many were truly positive?</p>
<p><span class="math display">\[\text{Precision} = \frac{TP}{TP+FP}\]</span></p>
<p><strong>Recall</strong> asks: of all the observations that were truly positive (Class 1), how many did the classifier predict to be positive?</p>
<p><span class="math display">\[\text{Recall} = \frac{TP}{TP+FN}\]</span></p>
<p>Notice that precision and recall take slightly different approaches to quantifying how well the model performs. Precision examines all of the positive <em>predictions</em> made by the model; recall examines the <em>datapoints</em> that were truly positive.</p>
<p>In practice, we would like our classifier to have both high precision and high recall. This can sometimes be a challenging goal. Precision penalizes false positives – as the number of false positives increases, the precision decreases. We might try to improve precision by reducing the number of positive predictions we make (and, at the same time, increasing the number of negative predictions).</p>
<p>In contrast, recall penalizes false negatives – as the number of false negatives increases, the recall decreases. To avoid false negatives, we might increase the number of positive predictions we make while decreasing the number of negative predictions. This means that there is typically a <em>trade-off</em> when trying to maximize both precision and recall.</p>
<p>So, should we prioritize precision or recall? It depends on the context. In many medical settings, there might be a much higher cost to “missing” positive cases by producing a false negative (for example, failing to detect a dangerous medical condition). In such situations, we may choose to focus on minimizing the number of false negatives by maximizing recall.</p>
</section>
<section id="false-positive-rates-and-true-positive-rates" class="level3" data-number="19.3.4">
<h3 data-number="19.3.4" class="anchored" data-anchor-id="false-positive-rates-and-true-positive-rates"><span class="header-section-number">19.3.4</span> False Positive Rates and True Positive Rates</h3>
<p>Let’s introduce two more metrics.</p>
<p>The <strong>false positive rate (FPR)</strong> asks: out of all datapoints that were truly negative (Class 0), how many did the classifier <em>incorrectly</em> predict to be positive?</p>
<p><span class="math display">\[\text{FPR} = \frac{FP}{FP+TN}\]</span></p>
<p>A similar metric is the <strong>true positive rate (TPR)</strong>, which finds the proportion of datapoints that were truly positive that the classifier correctly identified as positive. It is the same as recall defined above.</p>
<p><span class="math display">\[\text{FPR} = \frac{TP}{TP+FN}\]</span></p>
</section>
</section>
<section id="changing-the-classification-threshold" class="level2" data-number="19.4">
<h2 data-number="19.4" class="anchored" data-anchor-id="changing-the-classification-threshold"><span class="header-section-number">19.4</span> Changing the Classification Threshold</h2>
<p>Up until now, we have always been applying decision rules with a threshold of <span class="math inline">\(T=0.5\)</span>. When a predicted probability <span class="math inline">\(p\)</span> was equal to or greater than <span class="math inline">\(0.5\)</span> we predicted Class 1; otherwise, we predicted Class 0.</p>
<p>What happens when we change this threshold to some other value?</p>
<p>Consider first the case where we lower the threshold to <span class="math inline">\(T=0.25\)</span>. Any time the predicted probability of a datapoint belonging to Class 1 is greater than or equal to 0.25, the classifier will predict <span class="math inline">\(\hat{Y}=1\)</span>. In other words, if the classifier predicts a 25% chance or higher of a datapoint being positive, it will classify the point as being Class 1.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> (p<span class="op">&gt;=</span><span class="fl">0.25</span>).astype(<span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>theta0 <span class="op">=</span> model.intercept_</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>theta1 <span class="op">=</span> model.coef_[<span class="dv">0</span>]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>decision_boundary_T25 <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>theta1)<span class="op">*</span>(<span class="op">-</span>np.log(<span class="dv">1</span><span class="op">/</span><span class="fl">0.25</span> <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> theta0)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>sns.stripplot(x<span class="op">=</span>games[<span class="st">"GOAL_DIFF"</span>], y<span class="op">=</span>games[<span class="st">"WON"</span>], hue<span class="op">=</span>y_hat, orient<span class="op">=</span><span class="st">"h"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x, sigmoid(model.intercept_ <span class="op">+</span> model.coef_[<span class="dv">0</span>]<span class="op">*</span>x), <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"P(Y=1|x)"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="ss">f"Decision Boundary:</span><span class="ch">\n</span><span class="ss">x = </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">round</span>(decision_boundary_T25[<span class="dv">0</span>], <span class="dv">3</span>)<span class="sc">}</span><span class="ss">"</span>, (<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.5</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-18-output-1.png" width="576" height="429"></p>
</div>
</div>
<p>Notice that <em>more</em> datapoints are predicted to be Class 1 than when we used the threshold <span class="math inline">\(T=0.5\)</span>. This is because the model needs to be less “confident” before making a positive prediction – the predicted probability of being Class 1 only needs to be 25% or higher for a positive prediction. Also observe that the decision boundary has shifted left of its original position when <span class="math inline">\(T=0.5\)</span>. Changing the threshold value if <em>equivalent to shifting the decision boundary</em>.</p>
<p>When we raise the threshold to <span class="math inline">\(T=0.75\)</span>, we see the opposite behavior. The model will only predict Class 1 if there is a predicted 75% chance or higher of a datapoint belonging to Class 1, so we see fewer positive predictions. The decision boundary shifts right relative to the previous example.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> (p<span class="op">&gt;=</span><span class="fl">0.75</span>).astype(<span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>theta0 <span class="op">=</span> model.intercept_</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>theta1 <span class="op">=</span> model.coef_[<span class="dv">0</span>]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>decision_boundary_T75 <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>theta1)<span class="op">*</span>(<span class="op">-</span>np.log(<span class="dv">1</span><span class="op">/</span><span class="fl">0.75</span> <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> theta0)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>sns.stripplot(x<span class="op">=</span>games[<span class="st">"GOAL_DIFF"</span>], y<span class="op">=</span>games[<span class="st">"WON"</span>], hue<span class="op">=</span>y_hat, orient<span class="op">=</span><span class="st">"h"</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x, sigmoid(model.intercept_ <span class="op">+</span> model.coef_[<span class="dv">0</span>]<span class="op">*</span>x), <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"P(Y=1|x)"</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="ss">f"Decision Boundary:</span><span class="ch">\n</span><span class="ss">x = </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">round</span>(decision_boundary_T75[<span class="dv">0</span>], <span class="dv">3</span>)<span class="sc">}</span><span class="ss">"</span>, (<span class="fl">0.1</span>, <span class="fl">0.5</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-20-output-1.png" width="576" height="429"></p>
</div>
</div>
<p>Taken together, we see that the value of the threshold <span class="math inline">\(T\)</span> determines the relative number of positive and negative predictions.</p>
<p>How does changing the threshold impact the model’s performance? It depends on our dataset, as well as which metric we are considering. Let’s consider the accuracy of our logistic regression model on the <code>games</code> data. In the cell below, we test out many different possible values for the threshold. For each threshold value <span class="math inline">\(T\)</span>, we compute what accuracy our model achieves if we use that value <span class="math inline">\(T\)</span> in our decision rule.</p>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define performance metrics dependent on the threshold value</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_threshold(model, X, T): </span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    prob_one <span class="op">=</span> model.predict_proba(X)[:, <span class="dv">1</span>]</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (prob_one <span class="op">&gt;=</span> T).astype(<span class="bu">int</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> accuracy_threshold(X, Y, T):</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(predict_threshold(model, X, T) <span class="op">==</span> Y)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> precision_threshold(X, Y, T):</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    Y_hat <span class="op">=</span> predict_threshold(model, X, T)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>((Y_hat <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (Y <span class="op">==</span> <span class="dv">1</span>)) <span class="op">/</span> np.<span class="bu">sum</span>(Y_hat <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> recall_threshold(X, Y, T):</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    Y_hat <span class="op">=</span> predict_threshold(model, X, T)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>((Y_hat <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (Y <span class="op">==</span> <span class="dv">1</span>)) <span class="op">/</span> np.<span class="bu">sum</span>(Y <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tpr_threshold(X, Y, T): <span class="co"># Same as recall</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    Y_hat <span class="op">=</span> predict_threshold(model, X, T)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>((Y_hat <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (Y <span class="op">==</span> <span class="dv">1</span>)) <span class="op">/</span> np.<span class="bu">sum</span>(Y <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fpr_threshold(X, Y, T):</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    Y_hat <span class="op">=</span> predict_threshold(model, X, T)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>((Y_hat <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (Y <span class="op">==</span> <span class="dv">0</span>)) <span class="op">/</span> np.<span class="bu">sum</span>(Y <span class="op">==</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute accuracies for different thresholds</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>thresholds <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>accs <span class="op">=</span> [accuracy_threshold(X, Y, t) <span class="cf">for</span> t <span class="kw">in</span> thresholds]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot accuracy as a function of the threshold</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, accs)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Threshold"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Accuracy"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-22-output-1.png" width="597" height="429"></p>
</div>
</div>
<p>With higher threshold values, we make fewer positive predictions (reducing the risk of false positives) but more negative predictions (increasing the risk of false negatives). With lower threshold values, the converse is true – we make more positive predictions and fewer negative predictions. Because the relative numbers of false negatives and positives change with each threshold value, the accuracy of the classifier varies with the threshold. It turns out that for our specific model and dataset, the threshold value that maximizes accuracy is a bit under <span class="math inline">\(0.5\)</span>.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Threshold that maximizes accuracy: T = </span><span class="sc">{</span>thresholds[np.argmax(accs)]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Threshold that maximizes accuracy: T = 0.48484848484848486</code></pre>
</div>
</div>
<p>Changing the threshold value also allows us to more clearly see the trade-off between precision and recall described earlier. As the threshold increases, fewer positive predictions are made, decreasing the chances of a false positive while increasing the chances of a false negative. This means that precision increases while recall decreases.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>precisions <span class="op">=</span> [precision_threshold(X, Y, t) <span class="cf">for</span> t <span class="kw">in</span> thresholds]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>recalls <span class="op">=</span> [recall_threshold(X, Y, t) <span class="cf">for</span> t <span class="kw">in</span> thresholds]</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, precisions, label<span class="op">=</span><span class="st">"Precision"</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, recalls, label<span class="op">=</span><span class="st">"Recall"</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Threshold"</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Precision/Recall"</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-24-output-1.png" width="589" height="429"></p>
</div>
</div>
<p>This means that we need to select our threshold value carefully as part of the model design process. If we are attempting to maximize the precision of our model, we may choose a large <span class="math inline">\(T\)</span>; if we are trying to maximize recall, we will likely choose a smaller <span class="math inline">\(T\)</span>.</p>
<p>A <strong>precision-recall curve</strong> visualizes the trade-off using a single graph trace. Each position on the precision-recall curve represents a possible choice of threshold value <span class="math inline">\(T\)</span>. We then plot the precision and recall that our model obtains when using that value for the threshold.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>plt.plot(recalls, precisions)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Recall"</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Precision"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-25-output-1.png" width="589" height="429"></p>
</div>
</div>
<p>Often, we may attempt to maximize both precision and recall by selecting a threshold value that produces a point on the “bulge” of the curve in the upper righthand corner. This represents a point where both precision and recall are relatively high.</p>
<p>Alternatively, we may wish to understand the false positive and true positive rates of our classifier. We do so by constructing a <strong>receiver operating characteristic (ROC) curve</strong>. The name “ROC” orignates from the original use of this technique to process radar signal in World War II.</p>
<p>In an ROC curve, we similarly trial many possible values for the threshold <span class="math inline">\(T\)</span>. For each possible <span class="math inline">\(T\)</span>, we compute the TPR and FPR.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>tprs <span class="op">=</span> [tpr_threshold(X, Y, t) <span class="cf">for</span> t <span class="kw">in</span> thresholds]</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>fprs <span class="op">=</span> [fpr_threshold(X, Y, t) <span class="cf">for</span> t <span class="kw">in</span> thresholds]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>plt.plot(fprs, tprs)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"FPR"</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"TPR"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-26-output-1.png" width="589" height="429"></p>
</div>
</div>
<p>Our goal is to maximize TPR while keeping FPR low. To do so, we select a threshold value corresponding to the bulging region in the upper lefthand corner, where we see large TPR values and small FPR values.</p>
<p>In an ideal world, we would be able to achieve a TPR of 1 (where we make no false negative predictions) and an FPR of 0 (where we make no false positive predictions). If we were to plot the ROC curve for such a classifier, it would look like a right angle. Notice that the optimal point in the lefthand corner corresponds to a TPR of 1 and FPR of 0.</p>
<center>
<img src="images/perfect.png" alt="perfect predictor" width="500">
</center>
<p>The area under the ROC curve of the perfect predictor is 1. One way of quantifying how close a real-world classifier is to being “perfect” is by computing the <strong>area under the curve (AUC)</strong>. The closer the AUC is to 1, the closer the classifier is performing to the ideal predictor.</p>
<p>If the best-case predictor behaves in the way outlined above, how does the <em>worst-case</em> predictor behave? In the absolute worst case, a predictor will predict randomly: it will generate predicted probabilities uniformly at random between 0 and 1, without considering the actual data it has been given. It can be shown that the random predictor generates an ROC curve where the FPR and TPR are equal at each possible threshold.</p>
<center>
<img src="images/random.png" alt="random predictor" width="500">
</center>
<p>The AUC of this worst-case random predictor is equal to 0.5: the area of the triangle outlined by its ROC curve. This is the worst possible AUC that can be achieved by a classifier.</p>
<p>This means that we have now set the bounds for the performance of a real-world classifier. When we create classifiers of our own, our AUCs will lie between 0.5 (the worst AUC) and 1 (the best AUC). Our goal is to design a model that can achieve an AUC close to 1.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../logistic_regression_1/logistic_reg_1.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression I</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sql_I/sql_I.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">SQL I</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>