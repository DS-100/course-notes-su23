<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Principles and Techniques of Data Science - 19&nbsp; Logistic Regression II</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../logistic_regression_1/logistic_reg_1.html" rel="prev">
<link href="../data100_logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Logistic Regression II</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../data100_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Principles and Techniques of Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/DS-100/course-notes-su23" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_lec/introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_1/pandas_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Pandas I</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_2/pandas_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Pandas II</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pandas_3/pandas_3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pandas III</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../eda/eda.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Cleaning and EDA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regex/regex.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Text Wrangling and Regular Expressions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../visualization_1/visualization_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Visualization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling/sampling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro_to_modeling/intro_to_modeling.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Modeling</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../constant_model_loss_transformations/loss_transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Constant Model, Loss, and Transformations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ols/ols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../gradient_descent/gradient_descent.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Gradient Descent</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../feature_engineering/feature_engineering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Sklearn and Feature Engineering</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../case_study_HCE/case_study_HCE.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Case Study in Human Contexts and Ethics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../cv_regularization/cv_reg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Cross Validation and Regularization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_1/probability_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Random Variables</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability_2/probability_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Model Bias, Variance, and Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_1/logistic_reg_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression I</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../logistic_regression_2/logistic_reg_2.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Logistic Regression II</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#decision-boundaries" id="toc-decision-boundaries" class="nav-link active" data-scroll-target="#decision-boundaries"><span class="toc-section-number">19.1</span>  Decision Boundaries</a></li>
  <li><a href="#linear-separability" id="toc-linear-separability" class="nav-link" data-scroll-target="#linear-separability"><span class="toc-section-number">19.2</span>  Linear Separability</a>
  <ul>
  <li><a href="#defining-separability" id="toc-defining-separability" class="nav-link" data-scroll-target="#defining-separability"><span class="toc-section-number">19.2.1</span>  Defining Separability</a></li>
  <li><a href="#the-need-for-regularization" id="toc-the-need-for-regularization" class="nav-link" data-scroll-target="#the-need-for-regularization"><span class="toc-section-number">19.2.2</span>  The Need for Regularization</a></li>
  </ul></li>
  <li><a href="#performance-metrics" id="toc-performance-metrics" class="nav-link" data-scroll-target="#performance-metrics"><span class="toc-section-number">19.3</span>  Performance Metrics</a>
  <ul>
  <li><a href="#the-confusion-matrix" id="toc-the-confusion-matrix" class="nav-link" data-scroll-target="#the-confusion-matrix"><span class="toc-section-number">19.3.1</span>  The Confusion Matrix</a></li>
  <li><a href="#accuracy-precision-and-recall" id="toc-accuracy-precision-and-recall" class="nav-link" data-scroll-target="#accuracy-precision-and-recall"><span class="toc-section-number">19.3.2</span>  Accuracy, Precision, and Recall</a>
  <ul>
  <li><a href="#example-calculation" id="toc-example-calculation" class="nav-link" data-scroll-target="#example-calculation"><span class="toc-section-number">19.3.2.1</span>  Example Calculation</a>
  <ul class="collapse">
  <li><a href="#model-1" id="toc-model-1" class="nav-link" data-scroll-target="#model-1"><span class="toc-section-number">19.3.2.1.1</span>  Model 1</a></li>
  <li><a href="#model-2" id="toc-model-2" class="nav-link" data-scroll-target="#model-2"><span class="toc-section-number">19.3.2.1.2</span>  Model 2</a></li>
  </ul></li>
  <li><a href="#precision-vs-recall" id="toc-precision-vs-recall" class="nav-link" data-scroll-target="#precision-vs-recall"><span class="toc-section-number">19.3.2.2</span>  Precision vs Recall</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#adjusting-the-classification-threshold" id="toc-adjusting-the-classification-threshold" class="nav-link" data-scroll-target="#adjusting-the-classification-threshold"><span class="toc-section-number">19.4</span>  Adjusting the Classification Threshold</a>
  <ul>
  <li><a href="#two-more-metrics" id="toc-two-more-metrics" class="nav-link" data-scroll-target="#two-more-metrics"><span class="toc-section-number">19.4.1</span>  Two More Metrics</a></li>
  <li><a href="#the-roc-curve" id="toc-the-roc-curve" class="nav-link" data-scroll-target="#the-roc-curve"><span class="toc-section-number">19.4.2</span>  The ROC Curve</a></li>
  <li><a href="#precision-recall-curves" id="toc-precision-recall-curves" class="nav-link" data-scroll-target="#precision-recall-curves"><span class="toc-section-number">19.4.3</span>  Precision-Recall Curves</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Logistic Regression II</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Learning Outcomes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Apply decision rules to classify data</li>
<li>Recognize the need to regularize when working with linearly separable data</li>
<li>Compute performance metrics to quantify the quality of a classifier</li>
</ul>
</div>
</div>
</div>
<p>In the previous lecture, we made our way through the beginnings of the classification process. We reframed our understanding of the modeling process in terms of <em>predicted probabilities</em>. We then derived the logistic regression model to predict the probability of a datapoint belonging to Class 1, given inputted features.</p>
<p>In today’s lecture, we’ll address the second phase of a classification task: applying a decision rule to interpret these predicted probabilities and classify a datapoint. We’ll also explore metrics to assess the performance of our classifiers on real-world data.</p>
<p><img src="images/workflow.png" alt="classification workflow" width="750"></p>
<section id="decision-boundaries" class="level2" data-number="19.1">
<h2 data-number="19.1" class="anchored" data-anchor-id="decision-boundaries"><span class="header-section-number">19.1</span> Decision Boundaries</h2>
<p>To classify a datapoint as Class 1 or Class 0, we need to interpret the predicted probability outputted by our logistic regression model. We’ll do so by applying a <strong>decision rule</strong>: a rule that tells us, given a predicted probability <span class="math inline">\(p\)</span>, if we should predict <span class="math inline">\(\hat{Y}=1\)</span> or <span class="math inline">\(\hat{Y}=0\)</span>.</p>
<p>Decision rules are commonly implemented by defining a <strong>threshold</strong>. If the predicted probability is equal to or greater than the threshold value <span class="math inline">\(T\)</span>, we classify the datapoint into Class 1. Otherwise, we classify the datapoint into Class 0.</p>
<p><span class="math display">\[\hat{Y} = \text{classify}(x) = \begin{cases}
  \text{Class 1}  &amp; p \geq T \\
  \text{Class 0} &amp; p &lt; T
\end{cases}\]</span></p>
<p>The threshold <span class="math inline">\(T\)</span> is often 0.5, but not always. We’ll explore why we may apply different threshold values later this lecture.</p>
<p>Let’s try applying a threshold of <span class="math inline">\(T=0.5\)</span> to a logistic regression model fitted to our <code>games</code> data. As before, we will attempt to predict the outcome of a game (win or lose) given the <code>"GOAL_DIFF"</code> between teams.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>games <span class="op">=</span> pd.read_csv(<span class="st">"data/games"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> games[[<span class="st">"GOAL_DIFF"</span>]]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> games[<span class="st">"WON"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can create a logistic regression model in <code>sklearn</code> using the <code>LogisticRegression</code> class. It works very similarly to <code>LinearRegression</code>: we will initialize a model object, fit it, then use it to make predictions. Because we want to determine the <em>probabilities</em> predicted by our model, we will use the <code>.predict_proba()</code> method.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.linear_model <span class="im">as</span> lm</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a LogisticRegression object</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> lm.LogisticRegression()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model to the data</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>model.fit(X, Y)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities. We display only the first 5 rows for clarity</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>model.predict_proba(X)[:<span class="dv">5</span>, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>array([[0.9521269 , 0.0478731 ],
       [0.94399293, 0.05600707],
       [0.94208808, 0.05791192],
       [0.94208808, 0.05791192],
       [0.93384531, 0.06615469]])</code></pre>
</div>
</div>
<p>What’s going on here – why did we output a 2D array? By default, <code>.predict_proba()</code> will produce the predicted probability of a datapoint belonging to Class 0 <em>as well as</em> the probability of it belonging to Class 1. Notice that each row in the output above sums to 1.</p>
<p>To check which column represents which probability, we can call the <code>.classes_</code> attribute. The output below tells us that the first column of <code>.predict_proba()</code> represents the probability of belonging to Class 0, while the second column is the probability of belonging to Class 1.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model.classes_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>array([0, 1])</code></pre>
</div>
</div>
<p>Let’s grab just the predicted probabilities of each datapoint belonging to Class 1: <span class="math inline">\(p=P(Y=1|x)\)</span>.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> model.predict_proba(X)[:, <span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To categorize our datapoints into classes, we need to apply our decision rule. Recall that we are using a threshold of <span class="math inline">\(T=0.5\)</span>: this means that if the predicted probability for a datapoint is equal to or greater than <span class="math inline">\(0.5\)</span>, we’ll classify that point into Class 1.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># .astype(int) converts True and False to 1 and 0</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>(p <span class="op">&gt;=</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>array([0, 0, 0, ..., 1, 1, 1])</code></pre>
</div>
</div>
<p>Alternatively, the <code>.predict()</code> method of <code>LogisticRegression</code> will automatically apply a <span class="math inline">\(T=0.5\)</span> threshold for us.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> model.predict(X)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>games[<span class="st">"Predicted Class"</span>] <span class="op">=</span> classes</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize our results</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>z))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>sns.stripplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, y<span class="op">=</span><span class="st">"WON"</span>, hue<span class="op">=</span><span class="st">"Predicted Class"</span>, orient<span class="op">=</span><span class="st">"h"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.plot(x, sigmoid(model.intercept_ <span class="op">+</span> model.coef_[<span class="dv">0</span>]<span class="op">*</span>x), <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"P(Y=1|x)"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-8-output-1.png" width="576" height="429"></p>
</div>
</div>
<p>In the cell above, we color each datapoint according to the class predicted by our model. We have also superimposed the fitted logistic regression curve.</p>
<p>Let’s break down what’s going on here. We said that any datapoint with a predicted probability equal to or greater than <span class="math inline">\(0.5\)</span> should be categorized into Class 1. Equivalently, we can express this by saying:</p>
<ol type="1">
<li>Determine the value of our input feature, <code>"GOAL_DIFF"</code>, that leads to a predicted probability of exactly 0.5</li>
<li>Look at the value of the input feature for each individual datapoint. If the input feature is <em>greater</em> in value than the critical value where the predicted probability is <span class="math inline">\(0.5\)</span>, predict Class 1. Otherwise, predict Class 0</li>
</ol>
<p><img src="images/db.png" alt="decision boundary" width="400"></p>
<p>Because we are now looking at the <em>features</em> of a datapoint when deciding which class to predict, it makes more sense to display only this input data. We do so by using a rugplot, which visualizes scatter points when we only have one variable.</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the decision boundary</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>theta0 <span class="op">=</span> model.intercept_</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>theta1 <span class="op">=</span> model.coef_[<span class="dv">0</span>]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>theta1)<span class="op">*</span>(<span class="op">-</span>np.log(<span class="dv">1</span><span class="op">/</span>T <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> theta0)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the classified data</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>sns.rugplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, hue<span class="op">=</span><span class="st">"Predicted Class"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>plt.scatter(x<span class="op">=</span>[db], y<span class="op">=</span>[<span class="fl">0.005</span>], c<span class="op">=</span><span class="st">"k"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="fl">0.1</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>plt.yticks([], [])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-9-output-1.png" width="549" height="429"></p>
</div>
</div>
<p>We have just uncovered our first example of a <strong>decision boundary</strong>. A decision boundary is a “line” that splits the data into classes based on its features. In the example above, the point marked in black is our decision boundary: we classify all datapoints to the right of the decision boundary as being Class 1, and all points to the left as being Class 0.</p>
<p>Why did we place “line” in quotes earlier? More formally, a decision boundary is a <strong>hyperplane</strong>: a linear combination of our model’s <span class="math inline">\(p\)</span> features, expressed in <span class="math inline">\(p\)</span> dimensions. In the example above, we had a model with one feature, so our decision boundary is a 1-dimensional point. If we had two features, our decision boundary would be a 2-dimensional line. Similarly, for a model with <span class="math inline">\(p\)</span> features, our decision boundary is a hyperplane in <span class="math inline">\(p\)</span> dimensions.</p>
<p>Let’s consider the decision boundary of a model with an intercept term and <em>two</em> features – <code>"GOAL_DIFF"</code> and <code>"AST"</code>, which stands for the number of assists in a basketball game. Our logistic regression model for the probability of a team winning looks like:</p>
<p><span class="math display">\[p=\frac{1}{1+e^{-(\theta_0+\theta_1\text{GOAL\_DIFF}+\theta_2\text{AST})}}\]</span></p>
<p>The decision boundary represents all combinations of feature values that result in a predicted probability <em>exactly</em> equal to our threshold, <span class="math inline">\(T\)</span>. We can use this fact to derive the equation of our decision boundary hyperplane.</p>
<p><span class="math display">\[T=\frac{1}{1+e^{-(\theta_0+\theta_1\text{GOAL\_DIFF}+\theta_2\text{AST})}}\]</span> <span class="math display">\[\theta_0+\theta_1\text{GOAL\_DIFF}+\theta_2\text{AST} = -\log{(\frac{1}{T}-1)}\]</span></p>
<p>In the cell below, we plot the classifications made by our decision rule when <span class="math inline">\(T=0.5\)</span>. Notice that we are visualizing the decision boundary in terms of the <em>features</em> – we do not express boundaries in terms of <span class="math inline">\(Y\)</span>!</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X_two_feature <span class="op">=</span> games[[<span class="st">"GOAL_DIFF"</span>, <span class="st">"AST"</span>]]</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> games[<span class="st">"WON"</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>two_feature_model <span class="op">=</span> lm.LogisticRegression()</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>two_feature_model.fit(X_two_feature, Y)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># This function plots the decision boundary such that AST is a function of GOAL_DIFF</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>theta0 <span class="op">=</span> two_feature_model.intercept_</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>theta1, theta2 <span class="op">=</span> two_feature_model.coef_[<span class="dv">0</span>]</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="kw">lambda</span> goal_diff: (<span class="dv">1</span><span class="op">/</span>theta2)<span class="op">*</span>(<span class="op">-</span>np.log(<span class="dv">1</span><span class="op">/</span>T <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> theta1<span class="op">*</span>goal_diff <span class="op">-</span> theta0)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>games[<span class="st">"Predicted Class Two Features"</span>] <span class="op">=</span> two_feature_model.predict(X_two_feature)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, y<span class="op">=</span><span class="st">"AST"</span>, hue<span class="op">=</span><span class="st">"Predicted Class Two Features"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>plt.plot(x, db(x), <span class="st">"k"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-10-output-1.png" width="596" height="429"></p>
</div>
</div>
</section>
<section id="linear-separability" class="level2" data-number="19.2">
<h2 data-number="19.2" class="anchored" data-anchor-id="linear-separability"><span class="header-section-number">19.2</span> Linear Separability</h2>
<section id="defining-separability" class="level3" data-number="19.2.1">
<h3 data-number="19.2.1" class="anchored" data-anchor-id="defining-separability"><span class="header-section-number">19.2.1</span> Defining Separability</h3>
<p>Let’s see how well our decision boundary separates the data into classes. In the cell below, we overlay the decision boundary on top of the <em>true</em> classes of the dataset.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>games, x<span class="op">=</span><span class="st">"GOAL_DIFF"</span>, y<span class="op">=</span><span class="st">"AST"</span>, hue<span class="op">=</span><span class="st">"WON"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x, db(x), <span class="st">"k"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-11-output-1.png" width="596" height="429"></p>
</div>
</div>
<p>It turns out that our decision boundary doesn’t always get things “right.” Far away from the decision boundary, we see that most points are classified correctly. Closer to the hyperplane, however, there is a “muddled” region where some points with <span class="math inline">\(Y=1\)</span> sit to the left of the boundary, and some points with <span class="math inline">\(Y=0\)</span> sit to the right of the boundary.</p>
<p>This begs the question: in what situations can our classifier behave perfectly? That is, what does our data have to look like for us to be able to create a classifier that perfectly classifies all datapoints into the correct class?</p>
<p>A dataset is said to be <strong>linearly separable</strong> if there exists a hyperplane among the input features <span class="math inline">\(x\)</span> that <em>perfectly</em> separates the two classes <span class="math inline">\(Y\)</span>. Put more practically: we say that a dataset is linearly separable if we can draw a straight line, in terms of the features, that splits the two classes.</p>
<center>
<img src="images/separable.png" alt="linear separability" width="600">
</center>
</section>
<section id="the-need-for-regularization" class="level3" data-number="19.2.2">
<h3 data-number="19.2.2" class="anchored" data-anchor-id="the-need-for-regularization"><span class="header-section-number">19.2.2</span> The Need for Regularization</h3>
<p>When a dataset is linearly separable, we can create a classifier that perfectly separates the datapoints into classes.</p>
<p>If our classifier makes perfect classifications, does it also achieve 0 cross-entropy loss? To answer this question, consider the conditions under which cross-entropy loss approaches 0.</p>
<p><span class="math display">\[\text{Cross-Entropy Loss} = -\left(y\log{(p)}-(1-y)\log{(1-p)}\right)\]</span></p>
<p>For a single datapoint, cross-entropy loss is 0 if <span class="math inline">\(y=p\)</span>. That is:</p>
<ul>
<li>When the true class is 1, we incur zero loss if the model predicts a 100% probability of the datapoint belonging to Class 1</li>
<li>When the true class is 0, we incur zero loss of the model predicts a 0% probability of the datapoint belonging to Class 1</li>
</ul>
<p>When can our logistic regression model output predicted probabilities of exactly 0 or 1?</p>
<p><span class="math display">\[p=P(Y=1|x)=\frac{1}{1+e^{-x^{\top} \theta}}\]</span></p>
<p>When <span class="math inline">\(\theta \rightarrow \infty\)</span>, <span class="math inline">\(p \rightarrow 1\)</span>. Likewise, when <span class="math inline">\(\theta \rightarrow -\infty\)</span>, <span class="math inline">\(p \rightarrow 0\)</span>. Take a moment to examine the logistic regression model and convince yourself of these facts.</p>
<p>When our data is linearly separable, we run into the problem of <strong>diverging</strong> model parameters: the “optimal” parameters for the model approach positive or negative infinity. This can be a problem for a few reasons (beyond the fact that we can’t practically “plug” <span class="math inline">\(\infty\)</span> into our model to make predictions).</p>
<p>Consider an artificially-generated “toy” dataset of two datapoints.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#\code-fold: true</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>toy_df <span class="op">=</span> pd.DataFrame({<span class="st">"x"</span>: [<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], <span class="st">"y"</span>: [<span class="dv">0</span>, <span class="dv">1</span>]})</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>toy_df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">"y"</span>, s<span class="op">=</span><span class="dv">100</span>, legend<span class="op">=</span><span class="va">None</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-12-output-1.png" width="589" height="429"></p>
</div>
</div>
<p>If we fit a logistic regression model with one feature to this data, we find a strange-looking cross-entropy loss surface.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#\code-fold: true</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> toy_model(theta1, x):</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>theta1 <span class="op">*</span> x))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_cross_entropy_loss_toy(theta1):</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Here we use 1 - sigma(z) = sigma(-z) to improve numerical stability</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span> np.<span class="bu">sum</span>(toy_df[<span class="st">'y'</span>] <span class="op">*</span> np.log(toy_model(theta1, toy_df[<span class="st">'x'</span>])) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span><span class="op">-</span>toy_df[<span class="st">'y'</span>]) <span class="op">*</span> np.log(toy_model(theta1, <span class="op">-</span>toy_df[<span class="st">'x'</span>])))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>thetas <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">30</span>, <span class="dv">30</span>, <span class="dv">100</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> [mean_cross_entropy_loss_toy(theta) <span class="cf">for</span> theta <span class="kw">in</span> thetas]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.plot(thetas, losses, color <span class="op">=</span> <span class="st">'green'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r'Mean Cross Entropy Loss($\theta$)'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r'$\theta$'</span>)<span class="op">;</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Mean Cross Entropy Loss Surface"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="logistic_reg_2_files/figure-html/cell-13-output-1.png" width="587" height="449"></p>
</div>
</div>
<p>Though it’s difficult to see with the human eye, the “plateau” at large values of <span class="math inline">\(\theta\)</span> is very slightly tilted downwards. We can confirm this by examining a few values for the mean cross-entropy loss. Notice that each loss is very slightly smaller than the preceding loss value.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>losses[<span class="op">-</span><span class="dv">5</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>[2.1134205496775648e-12,
 1.1528555887710948e-12,
 6.288303211477875e-13,
 3.432809592141279e-13,
 1.869615573468851e-13]</code></pre>
</div>
</div>
<p>This means that if we were to use gradient descent to optimize the model parameter <span class="math inline">\(\theta\)</span>, our gradient descent algorithm would never converge. It would continue to follow this slope “downwards” in an ongoing attempt to reduce the mean cross-entropy loss.</p>
<p>What’s more, a model fitted with diverging parameters is <strong>overconfident</strong>. As a thought experiment, say we were somehow able to fit a model to our toy dataset with <span class="math inline">\(\theta=\infty\)</span>. If we ran our model on a new datapoint <span class="math inline">\((x=-0.5, y=1)\)</span>, the model would predict <span class="math inline">\(p=\frac{1}{1+e^{-\infty(-0.5)}}=0\)</span>. The cross-entropy loss on this new datapoint would be <span class="math inline">\(-\left((1)\log{(0)}-(1-1)\log{(1-0)}\right)=\infty\)</span>. In other words, our model would make such a poor prediction that it would incur <em>infinite</em> loss!</p>
<p>To avoid the problem of diverging model parameters, we always <em>regularize</em> logistic regression models. This constrains the magnitude of the parameters. Fortunately, <code>sklearn</code> automatically applies regularization when creating a <code>LogisticRegression</code> model.</p>
</section>
</section>
<section id="performance-metrics" class="level2" data-number="19.3">
<h2 data-number="19.3" class="anchored" data-anchor-id="performance-metrics"><span class="header-section-number">19.3</span> Performance Metrics</h2>
<p>Now that we have our classifier, let’s quantify how well it performs. The most basic evaluation metric is <strong>accuracy</strong> – the proportion of correctly classified points.</p>
<p><span class="math display">\[\text{accuracy} = \frac{\# \text{ of points classified correctly}}{\# \text{ of total points}}\]</span></p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>model.score(X, Y) <span class="co"># built-in accuracy function</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>0.7943089430894309</code></pre>
</div>
</div>
<p>However, accuracy is not always a great metric for classification, particularily when the data has class imbalance.</p>
<p>To understand why, let’s consider a classification problem with 100 emails, 5 of which are spam. We’ll investigate two models where accuracy is a poor metric.</p>
<ul>
<li><strong>Model 1</strong>: Our first model classifies every email as non-spam. The model’s accuracy is high (<span class="math inline">\(\frac{95}{100} = 0.95\)</span>), but it doesn’t detect any spam emails. Despite the high accuracy, this is a bad model.</li>
<li><strong>Model 2</strong>: The second model classifies every email as spam. The accuracy is low (<span class="math inline">\(\frac{5}{100} = 0.05\)</span>), but the model correctly labels every spam email. Unfortunately, it also misclassifies every non-spam email.</li>
</ul>
<section id="the-confusion-matrix" class="level3" data-number="19.3.1">
<h3 data-number="19.3.1" class="anchored" data-anchor-id="the-confusion-matrix"><span class="header-section-number">19.3.1</span> The Confusion Matrix</h3>
<p>Model 1 from above has 5 <strong>false negatives (FN)</strong> – data points which were predicted to belong to class <span class="math inline">\(0\)</span> (non-spam), but their true class was <span class="math inline">\(1\)</span> (spam). In a similar vein, Model 2 has 95 <strong>false positives (FP)</strong> – that is, “false alarms” where we predict class <span class="math inline">\(1\)</span>, but the true class was <span class="math inline">\(0\)</span>. <strong>True positives (TP)</strong> and <strong>true negatives (TN)</strong> are when we correctly classify observations as being positive or negative, respectively.</p>
<p>These classifications can be concisely summarized in a <strong>confusion matrix</strong>.</p>
<p><img src="images/confusion_matrix.png" alt="confusion_matrix" width="500"></p>
<p>An easy way to remember this terminology is as follows:</p>
<ol type="1">
<li>Look at the second word in the phrase. <em>Positive</em> means a prediction of 1. <em>Negative</em> means a prediction of 0.</li>
<li>Look at the first word in the phrase. <em>True</em> means our prediction was correct. <em>False</em> means it was incorrect.</li>
</ol>
<p>A confusion matrix for a particular classifier may be found programatically. For our breast cancer data, it looks like this:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>confusion_matrix(Y, y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>array([[511, 114],
       [139, 466]])</code></pre>
</div>
</div>
</section>
<section id="accuracy-precision-and-recall" class="level3" data-number="19.3.2">
<h3 data-number="19.3.2" class="anchored" data-anchor-id="accuracy-precision-and-recall"><span class="header-section-number">19.3.2</span> Accuracy, Precision, and Recall</h3>
<p>The purpose of our discussion of the confusion matrix was to motivate better performance metrics for classification problems with class imbalance - namely, precision and recall.</p>
<p><strong>Precision</strong> is defined as</p>
<p><span class="math display">\[\frac{\text{TP}}{\text{TP + FP}}\]</span></p>
<p>Precision answers the question: “of all observations that were predicted to be <span class="math inline">\(1\)</span>, what proportion were actually <span class="math inline">\(1\)</span>?” It measures how accurate the classifier is when its predictions are positive.</p>
<p><strong>Recall</strong> (or <strong>sensitivity</strong>) is defined as</p>
<p><span class="math display">\[\frac{\text{TP}}{\text{TP + FN}}\]</span></p>
<p>Recall aims to answer: “of all observations that were actually <span class="math inline">\(1\)</span>, what proportion were predicted to be <span class="math inline">\(1\)</span>?” It measures how many positive predictions were missed.</p>
<p>Here’s a helpful graphic that summarizes our discussion above.</p>
<p><img src="images/precision_recall_graphic.png" alt="confusion_matrix" width="700"></p>
<section id="example-calculation" class="level4" data-number="19.3.2.1">
<h4 data-number="19.3.2.1" class="anchored" data-anchor-id="example-calculation"><span class="header-section-number">19.3.2.1</span> Example Calculation</h4>
<p>In this section, we will calculate the accuracy, precision, and recall performance metrics for our earlier spam classification example. As a reminder, we had a 100 emails, 5 of which were spam. We designed two models:</p>
<ul>
<li>Model 1: Predict that every email is <em>non-spam</em></li>
<li>Model 2: Predict that every email is <em>spam</em></li>
</ul>
<section id="model-1" class="level5" data-number="19.3.2.1.1">
<h5 data-number="19.3.2.1.1" class="anchored" data-anchor-id="model-1"><span class="header-section-number">19.3.2.1.1</span> Model 1</h5>
<p>First, let’s begin by creating the confusion matrix.</p>
<table class="table">
<colgroup>
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>True Negative: 95</td>
<td>False Positive: 0</td>
</tr>
<tr class="even">
<td>1</td>
<td>False Negative: 5</td>
<td>True Positive: 0</td>
</tr>
</tbody>
</table>
<p>Convince yourself of why our confusion matrix looks like so.</p>
<p><span class="math display">\[\text{accuracy} = \frac{95}{100} = 0.95\]</span> <span class="math display">\[\text{precision} = \frac{0}{0 + 0} = \text{undefined}\]</span> <span class="math display">\[\text{recall} = \frac{0}{0 + 5} = 0\]</span></p>
<ul>
<li>Notice how our precision is undefined because we never predicted class <span class="math inline">\(1\)</span></li>
<li>Our recall is 0 for the same reason – the numerator is 0 (we had no positive predictions)</li>
</ul>
</section>
<section id="model-2" class="level5" data-number="19.3.2.1.2">
<h5 data-number="19.3.2.1.2" class="anchored" data-anchor-id="model-2"><span class="header-section-number">19.3.2.1.2</span> Model 2</h5>
<p>Our confusion matrix for Model 2 looks like so.</p>
<table class="table">
<colgroup>
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>True Negative: 0</td>
<td>False Positive: 95</td>
</tr>
<tr class="even">
<td>1</td>
<td>False Negative: 0</td>
<td>True Positive: 5</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\text{accuracy} = \frac{5}{100} = 0.05\]</span> <span class="math display">\[\text{precision} = \frac{5}{5 + 95} = 0.05\]</span> <span class="math display">\[\text{recall} = \frac{5}{5 + 0} = 1\]</span></p>
<ul>
<li>Our precision is low because we have many false positives</li>
<li>Our recall is perfect - we correctly classified all spam emails (we never predicted class <span class="math inline">\(0\)</span>)</li>
</ul>
</section>
</section>
<section id="precision-vs-recall" class="level4" data-number="19.3.2.2">
<h4 data-number="19.3.2.2" class="anchored" data-anchor-id="precision-vs-recall"><span class="header-section-number">19.3.2.2</span> Precision vs Recall</h4>
<p>Precision (<span class="math inline">\(\frac{\text{TP}}{\text{TP} + \textbf{ FP}}\)</span>) penalizes false positives, while recall (<span class="math inline">\(\frac{\text{TP}}{\text{TP} + \textbf{ FN}}\)</span>) penalizes false negatives.</p>
<p>In fact, precision and recall are <em>inversely related</em>. This is evident in our second model – we observed a high recall and low precision. Usually, there is a tradeoff in these two (most models can either minimize the number of FP or FN; and in rare cases, both).</p>
<p>The specific performance metric(s) to prioritize depends on the context. In many medical settings, there might be a much higher cost to missing positive cases. For instance, in our breast cancer example, it is more costly to misclassify malignant tumors (false negatives) than it is to incorrectly classify a benign tumor as malignant (false positives). In the case of the latter, pathologists can conduct further study to verify malignant tumors. As such, we should minimize the number of false negatives. This is equivalent to maximizing recall.</p>
</section>
</section>
</section>
<section id="adjusting-the-classification-threshold" class="level2" data-number="19.4">
<h2 data-number="19.4" class="anchored" data-anchor-id="adjusting-the-classification-threshold"><span class="header-section-number">19.4</span> Adjusting the Classification Threshold</h2>
<p>One way to minimize the number of FP vs.&nbsp;FN (equivalently, maximizing precision vs.&nbsp;recall) is by adjusting the classification threshold <span class="math inline">\(T\)</span>.</p>
<p><span class="math display">\[\hat y = \begin{cases}
        1, &amp; P(Y=1|x) \ge T\\
        0, &amp; \text{otherwise }
    \end{cases}\]</span></p>
<p>The default threshold in <code>sklearn</code> is <span class="math inline">\(T = 0.5\)</span>. As we increase the threshold <span class="math inline">\(T\)</span>, we “raise the standard” of how confident our classifier needs to be to predict 1 (i.e., “positive”).</p>
<p><img src="images/varying_threshold.png" alt="varying_threshold" width="800"></p>
<p>As you may notice, the choice of threshold <span class="math inline">\(T\)</span> impacts our classifier’s performance.</p>
<ul>
<li>High <span class="math inline">\(T\)</span>: Most predictions are <span class="math inline">\(0\)</span>.
<ul>
<li>Lots of false negatives</li>
<li>Fewer false positives</li>
</ul></li>
<li>Low <span class="math inline">\(T\)</span>: Most predictions are <span class="math inline">\(1\)</span>.
<ul>
<li>Lots of false positives</li>
<li>Fewer false negatives</li>
</ul></li>
</ul>
<p>In fact, we can choose a threshold <span class="math inline">\(T\)</span> based on our desired number, or proportion, of false positives and false negatives. We can do so using a few different tools. We’ll touch on two of the most important ones in Data 100.</p>
<ol type="1">
<li>Precision-Recall Curve (PR Curve). [Covered in Extra Content]</li>
<li>“Receiver Operating Characteristic” Curve (ROC Curve)</li>
</ol>
<p>To motivate the ROC Curve, let’s first consider two more metrics - true positive rate (TPR) and false positive rate (FPR).</p>
<section id="two-more-metrics" class="level3" data-number="19.4.1">
<h3 data-number="19.4.1" class="anchored" data-anchor-id="two-more-metrics"><span class="header-section-number">19.4.1</span> Two More Metrics</h3>
<p>The <strong>True Positive Rate (TPR)</strong> is defined as</p>
<p><span class="math display">\[\frac{\text{TP}}{\text{TP + FN}}\]</span></p>
<p>You’ll notice this is equivalent to <em>recall</em>. In the context of our spam email classifier, it answers the question: “what proportion of spam did I mark correctly?”.</p>
<ul>
<li>We’d like this to be close to <span class="math inline">\(1\)</span></li>
</ul>
<p>The <strong>False Positive Rate (FPR)</strong> is defined as</p>
<p><span class="math display">\[\frac{\text{FP}}{\text{FP + TN}}\]</span></p>
<p>Another word for FPR is <em>specificity</em>. This answers the question: “what proportion of regular email did I mark as spam?”</p>
<ul>
<li>We’d like this to be close to <span class="math inline">\(0\)</span></li>
</ul>
<p>As we increase threshold <span class="math inline">\(T\)</span>, both TPR and FPR decrease. We’ve plotted this relationship below for some model on a toy dataset.</p>
<p><img src="images/tpr_fpr.png" alt="tpr_fpr" width="800"></p>
</section>
<section id="the-roc-curve" class="level3" data-number="19.4.2">
<h3 data-number="19.4.2" class="anchored" data-anchor-id="the-roc-curve"><span class="header-section-number">19.4.2</span> The ROC Curve</h3>
<p>The “Receiver Operating Characteristic” Curve (<strong>ROC Curve</strong>) plots the tradeoff between FPR and TPR. Notice how the far-left of the curve corresponds to higher threshold <span class="math inline">\(T\)</span> values.</p>
<p><img src="images/roc_curve.png" alt="roc_curve" width="700"></p>
<p>The “perfect” classifier is the one that has a TPR of 1, and FPR of 0. This is achieved at the top-left of the plot below. More generally, it’s ROC curve resembles the curve in orange.</p>
<p><img src="images/roc_curve_perfect.png" alt="roc_curve_perfect" width="700"></p>
<p>We want our model to be as close to this orange curve as possible. How do we quantify “closeness”?</p>
<p>We can compute the <strong>area under curve (AUC)</strong> of the ROC curve. Notice how the perfect classifier has an AUC = 1. The closer our model’s AUC is to 1, the better it is. On the other hand, a terrible model will have an AUC closer to 0.5. This indicates the classifier is not able to distinguish between positive and negative classes, and thus, randomly predicts one of the two.</p>
<p><img src="images/roc_curve_worst_predictor.png" alt="roc_curve_worst_predictor" width="900"></p>
</section>
<section id="precision-recall-curves" class="level3" data-number="19.4.3">
<h3 data-number="19.4.3" class="anchored" data-anchor-id="precision-recall-curves"><span class="header-section-number">19.4.3</span> Precision-Recall Curves</h3>
<p>A <strong>Precision-Recall Curve (PR Curve)</strong> is an alternative to the ROC curve that displays the relationship between precision and recall for various threshold values. It is constructed in a similar way as with the ROC curve.</p>
<p>Let’s first consider how precision and recall change as a function of the threshold <span class="math inline">\(T\)</span>. We know this quite well from earlier – precision will generally increase, and recall will decrease.</p>
<p><img src="images/precision-recall-thresh.png" alt="precision-recall-thresh" width="750"></p>
<p>Displayed below is the PR-Curve for the same toy dataset. Notice how threshold values increase as we move to the left.</p>
<p><img src="images/pr_curve_thresholds.png" alt="pr_curve_thresholds" width="685"></p>
<p>Once again, the perfect classifier will resemble the orange curve, this time, facing the opposite direction.</p>
<p><img src="images/pr_curve_perfect.png" alt="pr_curve_perfect" width="675"></p>
<p>We want our PR-Curve to be as close to the “top right” of this graph as possible. Again, we use the AUC to determine “closeness”, with the perfect classifier exhibiting an AUC = 1 (and the worst with an AUC = 0.5).</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../logistic_regression_1/logistic_reg_1.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Logistic Regression I</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>