{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Text Wrangling and Regular Expressions\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 5\n",
    "    toc-location: right\n",
    "    code-fold: false\n",
    "    theme:\n",
    "      - cosmo\n",
    "      - cerulean\n",
    "    callout-icon: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "## Learning Outcomes\n",
    "- Understand Python string manipulation and `pandas` `str` methods for working with text data\n",
    "- Parse and create regex, with a reference table\n",
    "- Use vocabulary (closure, metacharater, groups, etc.) to describe regex metacharacters\n",
    ":::\n",
    "\n",
    "## Why Work with Text?\n",
    "\n",
    "Last lecture, we learned of the difference between quantitative and qualitative variable types. The latter of these variable types includes string data, which is the primary focus of today's lecture. In this note, we'll discuss the necessary tools to manipulate text: `pandas` string operations and regular expressions. \n",
    "\n",
    "We typically have one of two goals when working with text. \n",
    "\n",
    "1. Canonicalization: convert data that has multiple formats into a standard form.\n",
    "    - For example, to address datasets in which text values have inconsistent capitalization, whitespace, or use of symbols\n",
    "\n",
    "2. Extract information into a new feature.\n",
    "    - For example, to extract information about dates and times from a written text description\n",
    "\n",
    "## `.str` Methods in `pandas`\n",
    "\n",
    "In \"base\" Python, we have many built-in functions for manipulating string data. You likely encountered these in your introductory programming classes. A summary of common Python methods for operating on strings is given below. \n",
    "\n",
    "The limitation of Python's native functions for manipulating strings is that they are not designed to work at scale – Python assumes that we are operating on one string at a time, when, as data scientists, we may be working with large datasets of string data. Iterating over all string values in a `DataFrame` or `Series` is computationally expensive and may take too long to be of practical use.\n",
    "\n",
    "Fortunately, `pandas` offers a method of *vectorizing* string operations using the `.str` operator. Syntax of the form `Series.str` instructs `pandas` to act on a full *`Series`* of text data at once, without the need to iterate over individual values. A statement like `Series.str.string_function()` will then apply the string operation `string_function()` to *every* value contained in the Series.\n",
    "\n",
    "The table below provides an overview of common string functions. The \"Python\" column gives the usage of each function on an individual string `s`, while the \"`pandas`\" column shows the use of the `.str` operator to manipulate `Series` of strings.\n",
    "\n",
    "\n",
    "+-----------------------+-----------------+---------------------------+\n",
    "| Operation             | Python          |`pandas`                   |\n",
    "|                       |(single string)  |(`Series` of strings)      |\n",
    "+=======================+=================+===========================+\n",
    "| Transformation        | - `s.lower(_)`  | - `ser.str.lower(_)`      |\n",
    "|                       | - `s.upper(_)`  | - `ser.str.upper(_)`      |\n",
    "+-----------------------+-----------------+---------------------------+\n",
    "| Replacement + Deletion| - `s.replace(_)`| - `ser.str.replace(_)`    |\n",
    "|                       |                 |                           |\n",
    "+-----------------------+-----------------+---------------------------+\n",
    "| Split                 | - `s.split(_)`  | - `ser.str.split(_)`      |\n",
    "|                       |                 |                           |\n",
    "+-----------------------+-----------------+---------------------------+\n",
    "| Substring             | - `s[1:4]`      | - `ser.str[1:4]`          |\n",
    "|                       |                 |                           |\n",
    "+-----------------------+-----------------+---------------------------+\n",
    "| Membership            | - `'_' in s`    | - `ser.str.contains(_)`   |\n",
    "|                       |                 |                           |\n",
    "+-----------------------+-----------------+---------------------------+\n",
    "| Length                | - `len(s)`      | - `ser.str.len()`         |\n",
    "|                       |                 |                           |\n",
    "+-----------------------+-----------------+---------------------------+\n",
    "\n",
    "\n",
    "### Canonicalization\n",
    "With our new `.str` operator in hand, let's see how string methods allow us to achieve our two goals of working with text: canonicalization and extraction.\n",
    "\n",
    "Consider the following datasets containing information about counties. Although both `DataFrame`s include a \"County\" column, the county names are formatted differently. Attempting to merge the two `DataFrame`s fails because the two tables do not share commonly-formatted county names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Witt County</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lac qui Parle County</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis and Clark County</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St John the Baptist Parish</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       County State\n",
       "0              De Witt County    IL\n",
       "1        Lac qui Parle County    MN\n",
       "2      Lewis and Clark County    MT\n",
       "3  St John the Baptist Parish    LS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeWitt</td>\n",
       "      <td>16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lac Qui Parle</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis &amp; Clark</td>\n",
       "      <td>55716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St. John the Baptist</td>\n",
       "      <td>43044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 County  Population\n",
       "0                DeWitt       16798\n",
       "1         Lac Qui Parle        8067\n",
       "2         Lewis & Clark       55716\n",
       "3  St. John the Baptist       43044"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "import pandas as pd\n",
    "\n",
    "county_and_state = pd.read_csv('data/county_and_state.csv')\n",
    "county_and_pop = pd.read_csv('data/county_and_population.csv')\n",
    "\n",
    "display(county_and_state)\n",
    "display(county_and_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [County, State, Population]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we attempt to merge on the \"County\" column, common values cannot be found\n",
    "county_and_state.merge(county_and_pop, left_on=\"County\", right_on=\"County\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to assist with canonicalization of the `\"County\"` columns. `canonicalize_county_series` applies a sequence of `str` operations on an inputted `Series` to:\n",
    "\n",
    "* Convert the text to lowercase\n",
    "* Replace inconsistent uses of whitespace and symbols\n",
    "* Standardize the naming convention for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize_county_series(county_series):\n",
    "    return (\n",
    "        county_series\n",
    "            .str.lower()\n",
    "            .str.replace(' ', '', regex=True) #Specifying regex=True helps avoid a FutureWarning\n",
    "            .str.replace('&', 'and', regex=True)\n",
    "            .str.replace('.', '', regex=True)\n",
    "            .str.replace('county', '', regex=True)\n",
    "            .str.replace('parish', '', regex=True)\n",
    "    )\n",
    "\n",
    "county_and_pop['County'] = canonicalize_county_series(county_and_pop['County'])\n",
    "county_and_state['County'] = canonicalize_county_series(county_and_state['County'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our canonicalized county names can be successfully merged across the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dewitt</td>\n",
       "      <td>IL</td>\n",
       "      <td>16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lacquiparle</td>\n",
       "      <td>MN</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lewisandclark</td>\n",
       "      <td>MT</td>\n",
       "      <td>55716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stjohnthebaptist</td>\n",
       "      <td>LS</td>\n",
       "      <td>43044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             County State  Population\n",
       "0            dewitt    IL       16798\n",
       "1       lacquiparle    MN        8067\n",
       "2     lewisandclark    MT       55716\n",
       "3  stjohnthebaptist    LS       43044"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_and_state.merge(county_and_pop, left_on=\"County\", right_on=\"County\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction\n",
    "\n",
    "Now, let's experiment with an extraction task. Consider the following three pieces of text data, which are a log files from a computer operating system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['169.237.46.168 - - [26/Jan/2014:10:47:58 -0800] \"GET /stat141/Winter04/ HTTP/1.1\" 200 2585 \"http://anson.ucdavis.edu/courses/\"\\n',\n",
       " '193.205.203.3 - - [2/Feb/2005:17:23:6 -0800] \"GET /stat141/Notes/dim.html HTTP/1.0\" 404 302 \"http://eeyore.ucdavis.edu/stat141/Notes/session.html\"\\n',\n",
       " '169.237.46.240 - \"\" [3/Feb/2006:10:18:37 -0800] \"GET /stat141/homework/Solutions/hw1Sol.pdf HTTP/1.1\"\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/log.txt', 'r') as f:\n",
    "    log_lines = f.readlines()\n",
    "log_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to extract the day, month, year, hour, minutes, seconds, and timezone. Unfortunately, these items are not in a consistent position relative the beginning of the string, so slicing by some fixed offset won't work. For example, the date begins 21 characters from the start of the first string and 20 characters from the start of the second string.\n",
    "\n",
    "Instead, we can use some clever thinking. Notice how the relevant information is contained within a set of brackets, further seperated by `/` and `:`. We can hone in on this region of text, and split the data on these characters. Python's built-in `.split` function makes this easy.\n",
    "\n",
    "For simplicity, we'll only consider a single string, rather than an entire `Series` of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = log_lines[0] # Only considering the first row of data\n",
    "\n",
    "pertinent = first.split(\"[\")[1].split(']')[0]\n",
    "day, month, rest = pertinent.split('/')\n",
    "year, hour, minute, rest = rest.split(':')\n",
    "seconds, time_zone = rest.split(' ')\n",
    "day, month, year, hour, minute, seconds, time_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew, that was a lot of work! The logic above required a lot of manipulation to \"hack\" together the information we needed. The resulting code is verbose; that is, it required many lines of code to achieve a fairly simple task. This is a major limitation of both Python in-built functions and `pandas` `str` operations – they often don't generalize well to more complex patterns of storing text data.\n",
    "\n",
    "Fortunately, there is another way of working with patterns in text: regular expressions.\n",
    "\n",
    "## Regular Expressions\n",
    "\n",
    "A **regular expression (\"regex\")** is a sequence of characters that specifies a search pattern. They are written to extract specific information from text. Regular expressions are part of a smaller programming language embedded in Python, made available through the `re` module. As such, they have a stand-alone syntax and methods for various capabilities.\n",
    "\n",
    "What do regex patterns look like? An example is given in the code cell below. This pattern is designed to seek out US Social Security Numbers, which have the format \"###-##-####\". We'll discuss how this pattern was formed, as well as how to design patterns of your own, in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0-9]{3}-[0-9]{2}-[0-9]{4}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"[0-9]{3}-[0-9]{2}-[0-9]{4}\"\n",
    "\n",
    "# 3 of any digit, then a dash,\n",
    "# then 2 of any digit, then a dash,\n",
    "# then 4 of any digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many resources to learn and experiment with regular expressions. A few are provided below:\n",
    "\n",
    "- [Official Regex Guide](https://docs.python.org/3/howto/regex.html)\n",
    "- [Data 100 Reference Sheet](https://ds100.org/sp22/resources/assets/hw/regex_reference.pdf) \n",
    "- [Regex101.com](https://regex101.com/)\n",
    "    - Be sure to check Python as the \"flavor\" on the left.\n",
    "\n",
    "### Basic Regex Syntax\n",
    "\n",
    "There are four basic operations with regular expressions.\n",
    "\n",
    "#### Concatenation\n",
    "When a sequence of characters are listed in a regex pattern, regex will look for that literal sequence of characters in the text. \n",
    "\n",
    "For example, the regex pattern `AABAAB` will match the string \"AABAAB\".\n",
    "\n",
    "#### The OR operator: `|`\n",
    "A vertical bar `|` means \"or\" in regex. When `|` is included in a pattern, regex will look for the sequence of characters on its left, or the sequence of characters on its right.\n",
    "\n",
    "For example, the regex pattern `AA|BAAB` will match either the string \"AA\" or the string \"BAAB\". \n",
    "\n",
    "#### Zero or more: `*`\n",
    "An asterisk `*` means \"look for the preceding character, zero or more times.\" \n",
    "\n",
    "For example, the pattern `AB*A` will match \"AA\" (zero \"B\"s), \"ABA\" (one \"B\"), \"ABBA\" (two \"B\"s), and so on.\n",
    "\n",
    "#### Grouping: `( )`\n",
    "Parentheses are used to apply a regex operation to a group of characters. \n",
    "\n",
    "For example, the pattern `(AB)*A` applies the logic: \"look for 'AB' zero or more times, then look for an 'A'.\" It would match the strings \"A\" (zero \"AB\"s), \"ABA\" (1 \"AB\"), \"ABABA\" (2 \"AB\"s), and so on.\n",
    "\n",
    "The pattern `A(A|B)AAB` applies the logic: \"look for an 'A'. Then, look for an 'A' *or* a 'B'. Finally, look for 'AAB'.\" It matches the strings \"AAAAB\" or \"ABAAB\". \n",
    "\n",
    "Symbols like `*`, `( )`, and `|` are called **metacharacters** –– they represent a regex operation, rather than a literal tect character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Expanded\n",
    "The four basic regex operations can be combined with more advanced metacharacters to produce patterns of greater complexity. \n",
    "\n",
    "#### Wildcard: `.`\n",
    "A period is the \"wildcard\" character in regex – it represents *any* character. This is often used when we do not know in advance what specific characters we might encounter in our text data.\n",
    "\n",
    "For example, the pattern `.U.U.U.` matches any sequence that alternates between some character and the letter \"U\". The strings \"CUMULUS\" and \"JUGULUM\" would both be matched. \n",
    "\n",
    "#### One or more: `+`\n",
    "A plus sign is used to indicate that the preceding character should appear at least once in the string (contrast this to `*`, where the preceding character does not necessarily need to appear).\n",
    "\n",
    "For example, the pattern `AB+` matches any sequence of an \"A\" followed by one or more \"B\"s – the strings \"AB\", \"ABB\", and \"ABBB\" would all match.\n",
    "\n",
    "#### Repetition: `{ }`\n",
    "Curly braces are used to specify how many times the preceding character should appear. When a single number `a` is placed in curly brackets (`{a}`), the preceding character should appear exactly *a* times in the string. When two numbers `a` and `b` are placed in curly brackets (`{a, b}`), the preceding character should appear *between* `a` and `b` times in the string. \n",
    "\n",
    "For example, `AB{2}` matches \"ABB\". `AB{0, 2}` matches \"A\", \"AB\", or \"ABB\".\n",
    "\n",
    "#### Character class: `[ ]`\n",
    "A **character class** defines a set of characters belonging to the class. When placed in a regex pattern, the pattern will match *and* of the characters contained in the class. This makes character classes a powerful tool for cases where you know what the data *might* look like, but don't know the exact characters for certain. For example, we know that Social Security Numbers will always consist of numeric digits, but we don't know what specific numbers will appear in any one SSN. \n",
    "\n",
    "To define a character class, simply enclose the desired characters in square brackets, `[ ]`. For example, the pattern `\"[aeiou]\"` defines a character class that will match the letters \"a\", \"e\", \"i\", \"o\", or \"u\".\n",
    "\n",
    "Regex includes several pre-defined character classes. \n",
    "\n",
    "* `[A-Z]` includes any uppercase letter between \"A\" and \"Z\"\n",
    "* `[a-z]` includes any lowercase letter between \"a\" and \"z\"\n",
    "* `[0-9]` includes any numeric digit between 0 and 9\n",
    "* `[A-Za-z0-9]` includes all letters and all digits\n",
    "    \n",
    "Additionally, there are three metacharacters that provide shortcuts to common character classes.\n",
    " \n",
    "* `\\w` is equivalent to `[A-Za-z0-9]`\n",
    "* `\\d` is equifalent to `[0-9]`\n",
    "* `\\s` matches whitespace, such as spaces, tabs, and newlines\n",
    "    \n",
    "In some situations, we may want to match any character *other* than those included in a class. For example, we might want to match any character *other* than a numeric digit. We use a carat, `^`, to negate a character class. The pattern `[^0-9]` matches any character that is not a digit between 0 and 9. Similarly, we can use the capitalized forms of the character class metacharacters to indicate their negations.\n",
    "\n",
    "* `\\W` matches anything other than `[A-Za-z0-9]`\n",
    "* `\\D` matches anything other than `[0-9]`\n",
    "* `\\S` matches anything other than whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting a Regex Pattern\n",
    "\n",
    "At this point, we have the tools needed to write some fairly sophisticated patterns. The social security sumber pattern introduced at the start of this section no longer looks so foreign. Recall that our pattern took the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0-9]{3}-[0-9]{2}-[0-9]{4}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"[0-9]{3}-[0-9]{2}-[0-9]{4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can break this pattern down to interpret what it represents:\n",
    "\n",
    "* `[0-9]{3}`: look for a numeric digit, exactly 3 times\n",
    "* `-`: look for the literal character \"-\". We know this because \"-\" does not represent a regex metacharacter when not used inside of a character class.\n",
    "* `[0-9]{2}`: look for a numeric digit, exactly 2 times\n",
    "* `-`: look for the literal character \"-\"\n",
    "* `[0-9]{4}`: look for a numeric digit, exactly 4 times\n",
    "\n",
    "Put together, the pattern will match SSNs like \"555-12-8967\" and \"123-45-6789\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greediness\n",
    "\n",
    "There is one more important regex concept that we must consider before diving into patterns of our own: the concept of **greediness**. We say that regex uses \"greedy\" logic because it will *always* seek out the longest possible match in a string. \n",
    "\n",
    "Regex greediness is best illustrated through example. Let's consider the following problem: we want to match any lowercase alphabetic string that has a repeated vowel. For example, we want our pattern to match strings like \"noon\", \"peel\", \"festoon\", or \"oodles\". Take a moment to consider how you might approach this task.\n",
    "\n",
    "As a first attempt, you may have written a pattern that looked something like this (and, if you didn't, think about what reasoning is encoded in this pattern): `.*[aeiou]+.*`.\n",
    "Interpreted literally:\n",
    "\n",
    " * `.*`: look for any character, zero or more times\n",
    " * `[aeiou]+`: look for an \"a\", \"e\", \"i\", \"o\", or \"u\", one or more times\n",
    " * `.*`: look for any character, zero or more times\n",
    " \n",
    "At first blush, this pattern may seem like a fairly reasonable solution to the problem. However, something strange happens when we actually apply this pattern to a test string. In the code below, `r\".*[aeiou]+.*\"` represents our regex pattern, while `\"Only one word in this sentence seems like it should match.”` represents the string of data that the pattern will attempt to match. We'll discuss the functions used to apply regex patterns later.\n",
    "\n",
    "In the context of our goal from above, we only want to match the word \"seems\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Only one word in this sentence seems like it should match.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.search(r\".*[aeiou]+.*\", \"Only one word in this sentence seems like it should match.\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's strange – the regex pattern matches the entire sentence, rather than just the word \"seems\". The reason for this is regex's greediness. \n",
    "\n",
    "The figure below breaks down how regex will greedily interpret the pattern we dissected above. Specifically, the first `.*` will extend across *all* characters before the \"ee\" in the string, not just the \"s\" immediately before our repeated vowels. Likewise, the second `.*` will extend across *all* characters after the \"ee\" in the string, rather than just the \"ms\" after the vowels. \n",
    "\n",
    "![](images/greed.png)\n",
    "\n",
    "This means that we need to be mindful of regex's greed when we are only interested in a specific portion of a string. If we are not careful, we may end up with a substantially longer match than intended. \n",
    "\n",
    "The following pattern avoids the issue we ran into above by being more specific about what characters can and cannot be included in our text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seems'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"[a-z]*(aa|ee|ii|oo|uu)[a-z]*\", \"Only one word in this sentence seems like it should match.\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/vowels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Expanded (Expanded)\n",
    "\n",
    "One final batch of regex syntax.\n",
    "\n",
    "#### Escape character: `\\`\n",
    "Sometimes, we may wish to match the *literal* character associated with a regex metacharacter. For example, you may wish to extract a literal plus sign \"+\", rather than signify its metameaning \"one or more\". A backslash `\\` is used to \"escape out\" of a metacharacter. Regex will interpret the character following the backslash literally.\n",
    "\n",
    "The pattern `a\\+b` matches the string \"a+b\".\n",
    "\n",
    "#### End: `$`\n",
    "What if we only want to match characters if they appear at the end of a string? A dollar sign `$` is used to orient the regex pattern at the *end* of a test string. The pattern will only match if the characters in question appear at the end of the string.\n",
    "\n",
    "For example, the pattern `abc$` only matches text if the sequence \"abc\" appears at the end of the string data. The string \"123 abc\" satisfies this condition; the string \"abc 123\" does not.\n",
    "\n",
    "#### Start: `^`\n",
    "Similarly, we can specify that regex should only match patterns at the *start* of a string using a carat `^`. Notice that when we use `^` *outside* of a character class definition, it takes on a different meaning – it no longer represents the negation of a class.\n",
    "\n",
    "For example, the pattern `^abc` only matches text if the sequence \"abc\" appears at the start of the string data. The string \"abc 123\" satisfies this condition; the string \"123 abc\" does not.\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Operation                       | Example        | Matches           | Doesn't match       |\n",
    "|---------------------------------|----------------|-------------------|---------------------|\n",
    "| concatenation                   | `AABAAB`         | AABAAB            | every other string  |\n",
    "| or: `|`                         | `AA|BAAB`       | AA, BAAB           | every other string  |\n",
    "| zero or more: `*`               | `AB*A`           | AA, ABBA, ABBBBBA   | AB, ABABA            |\n",
    "| group: `( )`                    | `A(A|B)AAB`     | AAAAB, ABAAB       | every other string  |\n",
    "| any character: `.`              | `.U.U.U.`        | CUMULUS, JUGULUM   | SUCCUBUS, TUMULTUOUS |\n",
    "| character class: `[ ]`          | `[A-Za-z][a-z]*` | word, Capitalized  | camelCase, 4illegal  |\n",
    "| repeated exactly a times: `{a}` | `j[aeiou]{3}hn`  | jaoehn, jooohn     | jhn, jaeiouhn        |\n",
    "| repeated a to b times: `{a, b}` | `j[ou]{1,2}hn`   | john, juohn        | jhn, jooooohn        |\n",
    "| at least one: `+`               | `jo+hn`          | john, jooohn       | jhn, jjohn           |\n",
    "| beginning of string: `^`        | `^ark`           | ark two, ark o ark | dark                |\n",
    "| end of string: `$`              | `ark$`           | dark, ark o ark    | ark two             |\n",
    "| escape character: `\\`           | `cow\\.com`       | cow.com           | cowscom             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Functions\n",
    "\n",
    "With the foundations of regex in hand, let's start using our learning to create patterns of our own. To do so, we'll need to learn the Python functions for actually applying regex to text.\n",
    "\n",
    "Before we begin, we will introduce something called a **raw string**. We will usually use raw strings of the form `r\"a raw string\"` to construct a regex pattern, as opposed to \"standard\" strings of the form `\"a non-raw string\"`. The reason why is fairly tedious, and not in scope for Data 100. Put simply, a standard Python string interprets the character `\\` in a different way to how it is used in regex. Using raw strings avoids this issue.\n",
    "\n",
    "### Extraction\n",
    "The `re` module of Python allows us to use regex on individual strings. When working in `pandas`, `str` operations allow us to apply vectorized regex functions to `Series` of strings. \n",
    "\n",
    "To extract a regex match from a single string, we use the `re.findall` function. `re.findall` will return a list containing all matches of the regex pattern in a provided string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123-45-6789', '321-45-6789']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"My social security number is 123-45-6789 bro, or actually maybe it’s 321-45-6789.\";\n",
    "pattern = r\"[0-9]{3}-[0-9]{2}-[0-9]{4}\"\n",
    "\n",
    "re.findall(pattern, text)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` equivalent is `str.findall()`. The output of `Series.str.findall()` is a new `Series` containing lists of all matches contained in each string of the original `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "# Create a DataFrame of social security numbers to use as an example\n",
    "df_ssn = pd.DataFrame(\n",
    "    ['987-65-4321',\n",
    "     'forty',\n",
    "     '123-45-6789 bro or 321-45-6789',\n",
    "     '999-99-9999'],\n",
    "    columns=['SSN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       987-65-4321\n",
       "1                             forty\n",
       "2    123-45-6789 bro or 321-45-6789\n",
       "3                       999-99-9999\n",
       "Name: SSN, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example Series of social security numbers\n",
    "df_ssn[\"SSN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [987-65-4321]\n",
       "1                            []\n",
       "2    [123-45-6789, 321-45-6789]\n",
       "3                 [999-99-9999]\n",
       "Name: SSN, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using str.findall to extract SSNs\n",
    "df_ssn[\"SSN\"].str.findall(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capturing groups\n",
    "\n",
    "You might wonder: what if we only want to extract part of our full regex pattern? For example, what if we only wanted to return the middle two digits of each social security number?\n",
    "\n",
    "Regex uses a piece of syntax called a **capturing group** to specify what subset of a pattern should be \"captured\". Capturing groups are denoted by parentheses `( )`. Earlier, we used parentheses to outline the order of operations; depending on what regex function we use, parentheses can sometimes also be interpreted as capturing groups. `re.findall` and `str.findall` will both interpret parentheses as capturing groups.\n",
    "\n",
    "Consider the example text below. What if we wanted to extract the hour, minute, and second mentioned in the message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I will meet you at 08:30:00 pm tomorrow\"      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing groups help us extract *only* the information about the time from this string. Notice that only the values enclosed in parentheses in the regex pattern are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('08', '30', '00')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \".*(\\d\\d):(\\d\\d):(\\d\\d).*\"\n",
    "matches = re.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitution\n",
    "\n",
    "Another task we may encounter when working with text data is the need to substitute portions of a string with a different character. For example, we may want to replace messy HTML tags with an empty string to clean a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A messy string with extraneous HTML data\n",
    "text = \"<div><td valign='top'>Moo</td></div>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with individual strings, we use `re.sub`. The code below seeks out HTML tags denoted with angle brackets `< >` in the text and replaces them with empty strings. The first argument to the function is the regex pattern, the second is the string that should replace any matched text, and the third is the test string on which to run the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moo'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"<[^>]+>\"\n",
    "re.sub(pattern, \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorized `pandas` equivalent is `str.replace`. The first argument to the function is the regex pattern we wish to use; the second argument is the string that should replace the matched text. The `regex` parameter tells `str.replace` to expect a regex pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "# Create a DataFrame of HTML tags to use as an example\n",
    "df_html = pd.DataFrame(['<div><td valign=\"top\">Moo</td></div>',\n",
    "                   '<a href=\"http://ds100.org\">Link</a>',\n",
    "                   '<b>Bold text</b>'], columns=['Html'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <div><td valign=\"top\">Moo</td></div>\n",
       "1     <a href=\"http://ds100.org\">Link</a>\n",
       "2                        <b>Bold text</b>\n",
       "Name: Html, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example Series of HTML data\n",
    "df_html[\"Html\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Moo\n",
       "1         Link\n",
       "2    Bold text\n",
       "Name: Html, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_html[\"Html\"].str.replace(pattern, \"\", regex=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
